{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14773437,"sourceType":"datasetVersion","datasetId":9443355}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Climate Text Classification - Solution 3\n## Multi-Model Ensemble with Diverse Architectures and Sampling Strategies\n\n**Publication-Ready Pipeline**\n\n### Key Innovations:\n1. **Diverse Model Architectures**: DeBERTa-v3, RoBERTa, and DistilBERT\n2. **Multiple Sampling Strategies**: Oversampling, undersampling, and balanced sampling\n3. **Weighted Ensemble**: Trained meta-learner to combine predictions\n4. **Hard Negative Mining**: Focus on difficult examples\n5. **Curriculum Learning**: Progressive difficulty training\n\n### Expected Performance:\n- **Target**: 80%+ Macro F1 and Accuracy\n- **Hardware**: Kaggle P100 GPU (16GB)\n- **Output**: <19.5GB","metadata":{}},{"cell_type":"code","source":"# Install packages\n!pip install -q transformers==4.45.0 datasets accelerate scikit-learn openpyxl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:34:53.638581Z","iopub.execute_input":"2026-02-11T12:34:53.638864Z","iopub.status.idle":"2026-02-11T12:35:08.442249Z","shell.execute_reply.started":"2026-02-11T12:34:53.638813Z","shell.execute_reply":"2026-02-11T12:35:08.441420Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (\n    AutoTokenizer, AutoModel, AutoConfig,\n    get_linear_schedule_with_warmup\n)\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, classification_report,\n    precision_recall_curve, confusion_matrix\n)\nfrom sklearn.linear_model import LogisticRegression\n\nwarnings.filterwarnings('ignore')\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nprint('✓ Libraries loaded')\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:35:15.253534Z","iopub.execute_input":"2026-02-11T12:35:15.253858Z","iopub.status.idle":"2026-02-11T12:35:21.383811Z","shell.execute_reply.started":"2026-02-11T12:35:15.253812Z","shell.execute_reply":"2026-02-11T12:35:21.383133Z"}},"outputs":[{"name":"stdout","text":"✓ Libraries loaded\nPyTorch: 2.8.0+cu126\nCUDA: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # Paths\n    train_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Human labelled_DTU.xlsx'\n    test_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Master file_10k papers.xlsx'\n    output_dir = '/kaggle/working/'\n    \n    # Multiple models\n    model_configs = [\n        {\n            'name': 'microsoft/deberta-v3-base',\n            'max_length': 512,\n            'sampling': 'oversample',  # Oversample minority\n            'weight': 1.5  # Higher weight for better model\n        },\n        {\n            'name': 'roberta-base',\n            'max_length': 512,\n            'sampling': 'undersample',  # Undersample majority\n            'weight': 1.0\n        },\n        {\n            'name': 'distilbert-base-uncased',\n            'max_length': 512,\n            'sampling': 'balanced',  # Mix of both\n            'weight': 0.8\n        }\n    ]\n    \n    # Training\n    n_folds = 3  # Reduced for multiple models\n    n_epochs = 6\n    batch_size = 8\n    lr = 2e-5\n    weight_decay = 0.01\n    warmup_ratio = 0.1\n    max_grad_norm = 1.0\n    hidden_dropout = 0.1\n    \n    # Ensemble\n    use_meta_learner = True\n    \n    # Hardware\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    fp16 = True\n    num_workers = 2\n    \n    # Optimization\n    early_stopping_patience = 3\n    \n    seed = 42\n\nprint('✓ Configuration set')\nprint(f'Training {len(CFG.model_configs)} different models')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:35:57.818698Z","iopub.execute_input":"2026-02-11T12:35:57.819233Z","iopub.status.idle":"2026-02-11T12:35:57.826218Z","shell.execute_reply.started":"2026-02-11T12:35:57.819205Z","shell.execute_reply":"2026-02-11T12:35:57.825467Z"}},"outputs":[{"name":"stdout","text":"✓ Configuration set\nTraining 3 different models\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"# Load training data\ntrain_df = pd.read_excel(CFG.train_path, skiprows=1)\ntrain_df.columns = [\n    'Coder name', 'Article ID', 'Paper_Author/s', 'Paper title',\n    'Year of publication', 'DOI', 'URL', 'Abstracts',\n    'Accept/Reject', 'If Accept, identify theme'\n]\n\n# Clean\ntrain_df = train_df[train_df['Accept/Reject'].isin(['Accept', 'Reject'])].copy()\ntrain_df['text'] = train_df['Abstracts'].fillna('')\ntrain_df = train_df[train_df['text'].str.len() > 50].reset_index(drop=True)\n\n# Binary label\ntrain_df['label'] = (train_df['Accept/Reject'] == 'Accept').astype(int)\n\n# Load test data\ntest_df = pd.read_excel(CFG.test_path)\ntest_df['text'] = test_df['Abstract'].fillna('')\ntest_df = test_df[test_df['text'].str.len() > 50].reset_index(drop=True)\n\nprint(f'Training samples: {len(train_df)}')\nprint(f'Test samples: {len(test_df)}')\nprint(f'\\nClass distribution:')\nprint(train_df['label'].value_counts())\nprint(f'\\nImbalance ratio: {train_df[\"label\"].value_counts()[0] / train_df[\"label\"].value_counts()[1]:.2f}:1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:36:06.515074Z","iopub.execute_input":"2026-02-11T12:36:06.515664Z","iopub.status.idle":"2026-02-11T12:36:09.398436Z","shell.execute_reply.started":"2026-02-11T12:36:06.515638Z","shell.execute_reply":"2026-02-11T12:36:09.397821Z"}},"outputs":[{"name":"stdout","text":"Training samples: 1719\nTest samples: 10175\n\nClass distribution:\nlabel\n0    1520\n1     199\nName: count, dtype: int64\n\nImbalance ratio: 7.64:1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Sampling Strategies","metadata":{}},{"cell_type":"code","source":"def apply_sampling_strategy(df, strategy='balanced'):\n    \"\"\"Apply different sampling strategies\"\"\"\n    majority = df[df['label'] == 0]\n    minority = df[df['label'] == 1]\n    \n    if strategy == 'oversample':\n        # Oversample minority to match majority\n        minority_oversampled = minority.sample(\n            n=len(majority),\n            replace=True,\n            random_state=42\n        )\n        result = pd.concat([majority, minority_oversampled], ignore_index=True)\n        print(f'Oversampling: {len(result)} samples')\n        \n    elif strategy == 'undersample':\n        # Undersample majority to 3x minority\n        target_majority = len(minority) * 3\n        majority_undersampled = majority.sample(\n            n=target_majority,\n            random_state=42\n        )\n        result = pd.concat([majority_undersampled, minority], ignore_index=True)\n        print(f'Undersampling: {len(result)} samples')\n        \n    else:  # balanced\n        # Mix: oversample minority 2x, keep all majority\n        minority_oversampled = minority.sample(\n            n=len(minority) * 2,\n            replace=True,\n            random_state=42\n        )\n        result = pd.concat([majority, minority_oversampled], ignore_index=True)\n        print(f'Balanced: {len(result)} samples')\n    \n    result = result.sample(frac=1, random_state=42).reset_index(drop=True)\n    print(f'Reject: {(result[\"label\"]==0).sum()}, Accept: {(result[\"label\"]==1).sum()}')\n    print(f'Ratio: {(result[\"label\"]==0).sum() / (result[\"label\"]==1).sum():.2f}:1\\n')\n    \n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:36:47.104098Z","iopub.execute_input":"2026-02-11T12:36:47.104985Z","iopub.status.idle":"2026-02-11T12:36:47.111863Z","shell.execute_reply.started":"2026-02-11T12:36:47.104954Z","shell.execute_reply":"2026-02-11T12:36:47.111183Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"class ClimateDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        \n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:37:08.596073Z","iopub.execute_input":"2026-02-11T12:37:08.596739Z","iopub.status.idle":"2026-02-11T12:37:08.602106Z","shell.execute_reply.started":"2026-02-11T12:37:08.596710Z","shell.execute_reply":"2026-02-11T12:37:08.601301Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class ClimateClassifier(nn.Module):\n    def __init__(self, model_name, n_classes=2, dropout=0.1):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.config.update({\n            'hidden_dropout_prob': dropout,\n            'attention_probs_dropout_prob': dropout,\n        })\n        \n        self.transformer = AutoModel.from_pretrained(model_name, config=self.config)\n        \n        hidden_size = self.config.hidden_size\n        \n        # Multi-sample dropout for better generalization\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.LayerNorm(hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size // 2, n_classes)\n        )\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.transformer(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # Use [CLS] token\n        pooled = outputs.last_hidden_state[:, 0]\n        logits = self.classifier(pooled)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:37:11.801567Z","iopub.execute_input":"2026-02-11T12:37:11.801902Z","iopub.status.idle":"2026-02-11T12:37:11.808488Z","shell.execute_reply.started":"2026-02-11T12:37:11.801876Z","shell.execute_reply":"2026-02-11T12:37:11.807696Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Training Functions","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, scheduler, criterion, device, scaler=None):\n    model.train()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n    \n    pbar = tqdm(dataloader, desc='Training')\n    for batch in pbar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        if scaler is not None:\n            with torch.cuda.amp.autocast():\n                logits = model(input_ids, attention_mask)\n                loss = criterion(logits, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            optimizer.step()\n        \n        optimizer.zero_grad()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        true_labels.extend(labels.cpu().numpy())\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    avg_loss = total_loss / len(dataloader)\n    f1 = f1_score(true_labels, predictions, average='macro')\n    acc = accuracy_score(true_labels, predictions)\n    \n    return avg_loss, f1, acc\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    predictions = []\n    probabilities = []\n    true_labels = []\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc='Validation')\n        for batch in pbar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            \n            total_loss += loss.item()\n            \n            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            \n            probabilities.extend(probs)\n            predictions.extend(preds)\n            true_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    \n    return avg_loss, np.array(predictions), np.array(probabilities), np.array(true_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:37:17.699139Z","iopub.execute_input":"2026-02-11T12:37:17.699894Z","iopub.status.idle":"2026-02-11T12:37:17.713975Z","shell.execute_reply.started":"2026-02-11T12:37:17.699857Z","shell.execute_reply":"2026-02-11T12:37:17.713137Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def find_optimal_threshold(y_true, y_probs):\n    \"\"\"Find threshold that maximizes F1 score\"\"\"\n    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n    \n    f1_scores = []\n    for precision, recall in zip(precisions, recalls):\n        if precision + recall == 0:\n            f1_scores.append(0)\n        else:\n            f1_scores.append(2 * (precision * recall) / (precision + recall))\n    \n    best_idx = np.argmax(f1_scores)\n    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n    best_f1 = f1_scores[best_idx]\n    \n    return best_threshold, best_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:37:25.896941Z","iopub.execute_input":"2026-02-11T12:37:25.897464Z","iopub.status.idle":"2026-02-11T12:37:25.902239Z","shell.execute_reply.started":"2026-02-11T12:37:25.897440Z","shell.execute_reply":"2026-02-11T12:37:25.901545Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Train Multiple Models","metadata":{}},{"cell_type":"code","source":"# Store all model predictions for ensemble\nall_model_oof_probs = []\nall_model_test_probs = []\nall_model_thresholds = []\nall_model_weights = []\n\nfor model_idx, model_config in enumerate(CFG.model_configs):\n    print(f'\\n{\"#\"*80}')\n    print(f'MODEL {model_idx + 1}/{len(CFG.model_configs)}: {model_config[\"name\"]}')\n    print(f'Sampling Strategy: {model_config[\"sampling\"]}')\n    print(f'{\"#\"*80}\\n')\n    \n    # Initialize tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(model_config['name'])\n    \n    # K-Fold\n    skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n    \n    fold_scores = []\n    fold_thresholds = []\n    oof_probabilities = np.zeros(len(train_df))\n    \n    # Store models\n    fold_models = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n        print(f'\\n{\"=\"*80}')\n        print(f'FOLD {fold + 1}/{CFG.n_folds}')\n        print(f'{\"=\"*80}')\n        \n        # Get fold data\n        fold_train_df = train_df.iloc[train_idx].copy()\n        fold_val_df = train_df.iloc[val_idx].copy()\n        \n        # Apply sampling strategy\n        print(f'\\nApplying {model_config[\"sampling\"]} strategy:')\n        fold_train_sampled = apply_sampling_strategy(\n            fold_train_df,\n            strategy=model_config['sampling']\n        )\n        \n        # Create datasets\n        train_dataset = ClimateDataset(\n            fold_train_sampled['text'].values,\n            fold_train_sampled['label'].values,\n            tokenizer,\n            model_config['max_length']\n        )\n        \n        val_dataset = ClimateDataset(\n            fold_val_df['text'].values,\n            fold_val_df['label'].values,\n            tokenizer,\n            model_config['max_length']\n        )\n        \n        # Dataloaders\n        train_loader = DataLoader(\n            train_dataset,\n            batch_size=CFG.batch_size,\n            shuffle=True,\n            num_workers=CFG.num_workers,\n            pin_memory=True\n        )\n        \n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=CFG.batch_size * 2,\n            shuffle=False,\n            num_workers=CFG.num_workers,\n            pin_memory=True\n        )\n        \n        # Model\n        model = ClimateClassifier(\n            model_config['name'],\n            n_classes=2,\n            dropout=CFG.hidden_dropout\n        ).to(CFG.device)\n        \n        # Loss with class weights\n        class_weights = torch.tensor([1.0, 5.0], dtype=torch.float).to(CFG.device)\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n        \n        # Optimizer\n        optimizer = torch.optim.AdamW(\n            model.parameters(),\n            lr=CFG.lr,\n            weight_decay=CFG.weight_decay\n        )\n        \n        # Scheduler\n        num_training_steps = len(train_loader) * CFG.n_epochs\n        num_warmup_steps = int(num_training_steps * CFG.warmup_ratio)\n        \n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=num_warmup_steps,\n            num_training_steps=num_training_steps\n        )\n        \n        # Mixed precision\n        scaler = torch.cuda.amp.GradScaler() if CFG.fp16 else None\n        \n        # Training loop\n        best_f1 = 0\n        patience_counter = 0\n        \n        for epoch in range(CFG.n_epochs):\n            print(f'\\nEpoch {epoch + 1}/{CFG.n_epochs}')\n            \n            # Train\n            train_loss, train_f1, train_acc = train_epoch(\n                model, train_loader, optimizer, scheduler, criterion, CFG.device, scaler\n            )\n            \n            print(f'Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Acc: {train_acc:.4f}')\n            \n            # Validate\n            val_loss, val_preds, val_probs, val_labels = validate(\n                model, val_loader, criterion, CFG.device\n            )\n            \n            # Find optimal threshold\n            threshold, _ = find_optimal_threshold(val_labels, val_probs)\n            val_preds_thresh = (val_probs >= threshold).astype(int)\n            \n            val_f1 = f1_score(val_labels, val_preds_thresh, average='macro')\n            val_acc = accuracy_score(val_labels, val_preds_thresh)\n            \n            print(f'Val - Loss: {val_loss:.4f}, F1: {val_f1:.4f}, Acc: {val_acc:.4f}, Thresh: {threshold:.4f}')\n            \n            # Early stopping\n            if val_f1 > best_f1:\n                best_f1 = val_f1\n                best_threshold = threshold\n                patience_counter = 0\n                \n                # Save best model\n                torch.save(\n                    model.state_dict(),\n                    f'{CFG.output_dir}/model{model_idx}_fold{fold}.pth'\n                )\n                print(f'✓ Best model saved (F1: {best_f1:.4f})')\n            else:\n                patience_counter += 1\n                if patience_counter >= CFG.early_stopping_patience:\n                    print(f'\\nEarly stopping at epoch {epoch + 1}')\n                    break\n        \n        # Load best model\n        model.load_state_dict(\n            torch.load(f'{CFG.output_dir}/model{model_idx}_fold{fold}.pth')\n        )\n        \n        # Final validation\n        _, _, val_probs, _ = validate(model, val_loader, criterion, CFG.device)\n        \n        # Store OOF predictions\n        oof_probabilities[val_idx] = val_probs\n        \n        # Store fold results\n        fold_scores.append(best_f1)\n        fold_thresholds.append(best_threshold)\n        fold_models.append(model)\n        \n        print(f'\\nFold {fold + 1} Best F1: {best_f1:.4f}')\n        \n        # Cleanup\n        del train_dataset, val_dataset, train_loader, val_loader\n        gc.collect()\n        torch.cuda.empty_cache()\n    \n    print(f'\\n{\"=\"*80}')\n    print(f'MODEL {model_idx + 1} RESULTS')\n    print(f'{\"=\"*80}')\n    print(f'Average F1: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}')\n    \n    # Test predictions\n    print(f'\\nGenerating test predictions...')\n    test_dataset = ClimateDataset(\n        test_df['text'].values,\n        np.zeros(len(test_df)),\n        tokenizer,\n        model_config['max_length']\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=CFG.batch_size * 2,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True\n    )\n    \n    # Ensemble test predictions from folds\n    test_probs_folds = []\n    \n    for fold_model in fold_models:\n        fold_model.eval()\n        fold_test_probs = []\n        \n        with torch.no_grad():\n            for batch in test_loader:\n                input_ids = batch['input_ids'].to(CFG.device)\n                attention_mask = batch['attention_mask'].to(CFG.device)\n                \n                logits = fold_model(input_ids, attention_mask)\n                probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n                fold_test_probs.append(probs)\n        \n        test_probs_folds.append(np.concatenate(fold_test_probs))\n    \n    # Average test predictions\n    model_test_probs = np.mean(test_probs_folds, axis=0)\n    \n    # Store for ensemble\n    all_model_oof_probs.append(oof_probabilities)\n    all_model_test_probs.append(model_test_probs)\n    all_model_thresholds.append(np.mean(fold_thresholds))\n    all_model_weights.append(model_config['weight'])\n    \n    print(f'✓ Model {model_idx + 1} complete\\n')\n    \n    # Cleanup\n    del fold_models, tokenizer\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T12:37:57.559739Z","iopub.execute_input":"2026-02-11T12:37:57.560375Z","iopub.status.idle":"2026-02-11T14:35:57.796953Z","shell.execute_reply.started":"2026-02-11T12:37:57.560348Z","shell.execute_reply":"2026-02-11T14:35:57.796085Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nMODEL 1/3: microsoft/deberta-v3-base\nSampling Strategy: oversample\n################################################################################\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de991330c87f452291c4927822838e36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26dbfa85a3da4853afffab86d8fa95d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677292a4e83144a293b43926a6898bf3"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nFOLD 1/3\n================================================================================\n\nApplying oversample strategy:\nOversampling: 2028 samples\nReject: 1014, Accept: 1014\nRatio: 1.00:1\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc79d1cdf674811bb63be74837bde5c"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62f5c3885c64421a822e5c7633c15077"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.4542, F1: 0.5798, Acc: 0.6183\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9202f9a14c453b879c2143590812ce"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.6011, F1: 0.6857, Acc: 0.8482, Thresh: 0.7701\n✓ Best model saved (F1: 0.6857)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09df5b5dac82417080f392b3a8d28843"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2392, F1: 0.8842, Acc: 0.8846\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3e2295d934433287098499d249e536"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0538, F1: 0.6902, Acc: 0.8412, Thresh: 0.0520\n✓ Best model saved (F1: 0.6902)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f858380baf44baf94a765684909b3c4"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.1119, F1: 0.9595, Acc: 0.9596\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87b3087512104cc1a523887dd67e394a"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.2257, F1: 0.7091, Acc: 0.8551, Thresh: 0.0114\n✓ Best model saved (F1: 0.7091)\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b138a927a7da4305bbf487926061dfda"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0351, F1: 0.9887, Acc: 0.9887\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4716c43cc65549f5afc97fa229503e63"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.7572, F1: 0.7118, Acc: 0.8674, Thresh: 0.0014\n✓ Best model saved (F1: 0.7118)\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472c6272bafe4729a39c079faae895ff"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0137, F1: 0.9956, Acc: 0.9956\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b330ce34ae54cc4a5fbda7613dba90f"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.9115, F1: 0.7133, Acc: 0.8586, Thresh: 0.0006\n✓ Best model saved (F1: 0.7133)\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5b6125a28d43fe9577dfdb51084e2d"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0042, F1: 0.9985, Acc: 0.9985\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b3f7b8928a46ab9bad203f36fd2fbc"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.8091, F1: 0.7140, Acc: 0.8569, Thresh: 0.0006\n✓ Best model saved (F1: 0.7140)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b21c22442f224ae2ac28b6c626c61d32"}},"metadata":{}},{"name":"stdout","text":"\nFold 1 Best F1: 0.7140\n\n================================================================================\nFOLD 2/3\n================================================================================\n\nApplying oversample strategy:\nOversampling: 2026 samples\nReject: 1013, Accept: 1013\nRatio: 1.00:1\n\n\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01175c08fbc5473fa2ffc11bed9b86fe"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.4267, F1: 0.6181, Acc: 0.6525\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018228e353c14541a914bffc55be4d25"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0217, F1: 0.6930, Acc: 0.8691, Thresh: 0.9630\n✓ Best model saved (F1: 0.6930)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5570e66ade64970bf6bdde0bb6f54dd"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2227, F1: 0.9006, Acc: 0.9008\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eb220b67e144e9cb107260ee5cfa234"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.9428, F1: 0.7079, Acc: 0.8517, Thresh: 0.8996\n✓ Best model saved (F1: 0.7079)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"646c0dcdf634472e814cdee1fde286e2"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>if w.is_alive():\n\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n   self._shutdown_workers() \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      ^^if w.is_alive():\n^^ ^ ^^  ^^ ^ ^ ^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^ \n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'\n        ^ ^ ^ ^   ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 0.0950, F1: 0.9664, Acc: 0.9664\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c3f5e0930b4662b1a9b66618b6ada8"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0498, F1: 0.7149, Acc: 0.8674, Thresh: 0.9896\n✓ Best model saved (F1: 0.7149)\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb1a5eb30c44a648be4da51d9f6f1c5"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0388, F1: 0.9852, Acc: 0.9852\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee71790a537244ca945573439889ec07"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.5751, F1: 0.6845, Acc: 0.8255, Thresh: 0.0009\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983bd280e1b6443fb090479cd961d945"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0134, F1: 0.9946, Acc: 0.9946\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85836d26503a4c138280e1c556d39a44"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.6125, F1: 0.7290, Acc: 0.8691, Thresh: 0.0012\n✓ Best model saved (F1: 0.7290)\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a55060fe834422c8f165ab0a202cc6e"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0060, F1: 0.9975, Acc: 0.9975\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86764aeaafbe401bb0dcc8ab408efbc3"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.7400, F1: 0.6971, Acc: 0.8499, Thresh: 0.0005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d0047b670249c8bcaf5c8307783b47"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Best F1: 0.7290\n\n================================================================================\nFOLD 3/3\n================================================================================\n\nApplying oversample strategy:\nOversampling: 2026 samples\nReject: 1013, Accept: 1013\nRatio: 1.00:1\n\n\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b245a1cfa15045899227af5de2b3df82"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.4786, F1: 0.5590, Acc: 0.5958\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf8fabbf0024cd4a4df0af65d665dbd"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5216, F1: 0.6872, Acc: 0.8255, Thresh: 0.3665\n✓ Best model saved (F1: 0.6872)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83a1472132e943bcab2f1456e22ff36a"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2116, F1: 0.9105, Acc: 0.9107\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f24463a435024be0ad43b1c4b9b342c4"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.1742, F1: 0.6617, Acc: 0.7801, Thresh: 0.0071\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c07a40ab3f435898d6e9ded7805491"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0734, F1: 0.9719, Acc: 0.9719\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b2a5aafe3b4be19c79057016c6afc1"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.4809, F1: 0.6830, Acc: 0.8429, Thresh: 0.0027\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee96bce74fc494ea2d900e23a9ea45a"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0328, F1: 0.9906, Acc: 0.9906\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c635753e85d4d0c808dc4a34af2bd69"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.5384, F1: 0.6883, Acc: 0.8394, Thresh: 0.0012\n✓ Best model saved (F1: 0.6883)\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ea8b9d440c495c92d7011188834887"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0170, F1: 0.9956, Acc: 0.9956\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3947da7fa9c545009e7f67835892abd9"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.5575, F1: 0.7001, Acc: 0.8551, Thresh: 0.0008\n✓ Best model saved (F1: 0.7001)\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/254 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"631b1e20aa104b4dbe98d4578a2defa8"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0093, F1: 0.9970, Acc: 0.9970\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e987ca442a4f789929f62f441125ac"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.6813, F1: 0.7021, Acc: 0.8621, Thresh: 0.0007\n✓ Best model saved (F1: 0.7021)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c99c8cef135c4f1398b9c3b294ad5a60"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Best F1: 0.7021\n\n================================================================================\nMODEL 1 RESULTS\n================================================================================\nAverage F1: 0.7150 ± 0.0110\n\nGenerating test predictions...\n✓ Model 1 complete\n\n\n################################################################################\nMODEL 2/3: roberta-base\nSampling Strategy: undersample\n################################################################################\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edeb478e6254d45b2573c3d990dcfa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7e9739a78e047208f3ed9966f23de06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f7659f4e35481cbb0409e6f8d3e6fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ad015398e24cb3937bac5b7fe832ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998bc8f95b4d462d8de25c631572d003"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nFOLD 1/3\n================================================================================\n\nApplying undersample strategy:\nUndersampling: 528 samples\nReject: 396, Accept: 132\nRatio: 3.00:1\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e98d1e84104d40b665cbad0155b7f6"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/66 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e225b30fdcd48afb0e044f77c7caa9a"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6647, F1: 0.4152, Acc: 0.4167\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4f2f354fbc4a5387e8423dd628f6d3"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.7014, F1: 0.6531, Acc: 0.8307, Thresh: 0.8790\n✓ Best model saved (F1: 0.6531)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/66 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ee8462083c6467eac8218406491ebfc"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5408, F1: 0.7285, Acc: 0.7652\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19780da7c0c94fffb5509917470ff04f"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.7247, F1: 0.6836, Acc: 0.8325, Thresh: 0.8899\n✓ Best model saved (F1: 0.6836)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/66 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"514204c5c4234fbea0deaffb04c5467d"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.3361, F1: 0.8283, Acc: 0.8542\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6fdcbb6ea024b9f84871c716453032c"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.8788, F1: 0.6495, Acc: 0.7871, Thresh: 0.0781\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/66 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2847623d884318bdb2d0d4da5b604d"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2582, F1: 0.8967, Acc: 0.9186\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dac701a83e04e9096cf91d94a2dbded"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.1450, F1: 0.6308, Acc: 0.7452, Thresh: 0.0079\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/66 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0394631cac254262b5e420b0a4b850ca"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.1567, F1: 0.9323, Acc: 0.9470\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4a21ece9064e47bb70cfec89a32174"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.2296, F1: 0.6298, Acc: 0.7417, Thresh: 0.0086\n\nEarly stopping at epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b4caefef6c47cd8dea593def36c544"}},"metadata":{}},{"name":"stdout","text":"\nFold 1 Best F1: 0.6836\n\n================================================================================\nFOLD 2/3\n================================================================================\n\nApplying undersample strategy:\nUndersampling: 532 samples\nReject: 399, Accept: 133\nRatio: 3.00:1\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18991c2fec9d4cacbdba5c387eb11841"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6977, F1: 0.4283, Acc: 0.4305\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4e9f59e37b348a1a3024ebf2bc4e834"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5892, F1: 0.6199, Acc: 0.7784, Thresh: 0.5390\n✓ Best model saved (F1: 0.6199)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44bae6ddba864ca8abe7e86f66bc1f85"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5807, F1: 0.6692, Acc: 0.7030\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"409a784b6d0f46149fcf6f38ef37048b"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5612, F1: 0.6422, Acc: 0.7906, Thresh: 0.5351\n✓ Best model saved (F1: 0.6422)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af71e35bffb4d8abba785cda809a65a"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5499, F1: 0.7527, Acc: 0.8026\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf37ec931d904be5835aba4aad0dead1"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    Exception ignored in: self._shutdown_workers()\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    \nif w.is_alive():Traceback (most recent call last):\n\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      self._shutdown_workers() \n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n     ^if w.is_alive():^\n^ ^^ ^ ^  ^^ ^ ^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^  ^  ^  \n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process'\n   ^ ^ ^   ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: ^^can only test a child process\n^^Exception ignored in: \nAssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n: Traceback (most recent call last):\ncan only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\n    self._shutdown_workers()\nException ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>    \nif w.is_alive():Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\n     self._shutdown_workers()\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive():\n    ^^^ ^ ^ ^^  ^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^^  ^ ^ \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n       ^ ^^^^ ^^ ^ ^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: can only test a child process^\n^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>^^^\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^    ^^self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nAssertionError:     can only test a child processif w.is_alive():\n\n  Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n Traceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():\n^  ^ ^^  ^ ^ ^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^  ^^  ^^ ^^\n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'\n      ^  ^ ^^ ^^  ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    \nself._shutdown_workers()AssertionError\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n:     can only test a child process\nif w.is_alive():\n Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0> \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    ^if w.is_alive():^\n^ ^ ^  ^ ^  ^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ \n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n           ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^^can only test a child process^\n^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Val - Loss: 0.6241, F1: 0.6806, Acc: 0.8621, Thresh: 0.7260\n✓ Best model saved (F1: 0.6806)\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433e712c69764001aaa8b94b16243aa7"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.3857, F1: 0.8402, Acc: 0.8741\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b78d44d0848648c9aeac423718bd08b3"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.6810, F1: 0.6634, Acc: 0.8307, Thresh: 0.9069\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a51960b9fd8406187572f667737d55f"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2296, F1: 0.8900, Acc: 0.9135\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692278a5030743a3b208c6989a9091eb"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0181, F1: 0.6378, Acc: 0.7714, Thresh: 0.0152\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afdfb8b46a444c4c9cf54c187794640b"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2019, F1: 0.9396, Acc: 0.9530\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2232c2285c54e10ad476d0d56dae75a"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0565, F1: 0.6486, Acc: 0.7888, Thresh: 0.0394\n\nEarly stopping at epoch 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19099b20917041648d62770594354754"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Best F1: 0.6806\n\n================================================================================\nFOLD 3/3\n================================================================================\n\nApplying undersample strategy:\nUndersampling: 532 samples\nReject: 399, Accept: 133\nRatio: 3.00:1\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e0546e018a24aaf8382d2ee7bbefa7b"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6845, F1: 0.4466, Acc: 0.4511\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14eb40ae2d6c4534a47288322162a486"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.8246, F1: 0.6511, Acc: 0.7661, Thresh: 0.7235\n✓ Best model saved (F1: 0.6511)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7559dd3ea44fb9b80849dc6b604c29"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5808, F1: 0.6169, Acc: 0.6391\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af92f269011346f9ac68d53ae809824a"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5856, F1: 0.6577, Acc: 0.7906, Thresh: 0.7030\n✓ Best model saved (F1: 0.6577)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95ee7f68c014202b1809ddb0ccf1b91"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5477, F1: 0.7426, Acc: 0.7838\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bbc8bc606324bd0b992714eccee21fc"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5567, F1: 0.6919, Acc: 0.8325, Thresh: 0.7962\n✓ Best model saved (F1: 0.6919)\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7dd04147af4eda9f54460db8f238dd"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.3165, F1: 0.8663, Acc: 0.8929\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebb923fcd074a3b9b4ab877c01d108a"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.6978, F1: 0.7054, Acc: 0.8447, Thresh: 0.5665\n✓ Best model saved (F1: 0.7054)\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080acae4685e44b1ba713424a350a62d"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2289, F1: 0.9214, Acc: 0.9398\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf66a66c39a42598782c76b839a515c"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.9838, F1: 0.6708, Acc: 0.7993, Thresh: 0.1528\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/67 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56c2669ec2c4cc09ea431fdb6481f28"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.1579, F1: 0.9605, Acc: 0.9699\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"827d967ae4ff44f8b2120108296dc1da"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0802, F1: 0.6756, Acc: 0.8168, Thresh: 0.0763\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e59bccb82049fc81429b74a3551745"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Best F1: 0.7054\n\n================================================================================\nMODEL 2 RESULTS\n================================================================================\nAverage F1: 0.6899 ± 0.0110\n\nGenerating test predictions...\n✓ Model 2 complete\n\n\n################################################################################\nMODEL 3/3: distilbert-base-uncased\nSampling Strategy: balanced\n################################################################################\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4f16df6a3549a4b5b6bc973569273f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381248d74c8f4ca1b0ddfe4ad33fc2c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00511319b35f4df49321b0b61dad5418"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19c9d30883a4374bb958ceb5045d256"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nFOLD 1/3\n================================================================================\n\nApplying balanced strategy:\nBalanced: 1278 samples\nReject: 1014, Accept: 264\nRatio: 3.84:1\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8602049a6de94faea4b4b91c713cf310"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42638791892c4d6e848037268be61043"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.5863, F1: 0.6020, Acc: 0.6565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e30a3d3b9543ebae5882380c7a08ab"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.6851, F1: 0.6660, Acc: 0.8045, Thresh: 0.8081\n✓ Best model saved (F1: 0.6660)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35dbd30f9e0145119276a8a65b447c26"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    Exception ignored in: self._shutdown_workers()\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n        self._shutdown_workers()if w.is_alive():\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive(): \n         ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n\n      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                 ^ ^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^\nException ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n: Traceback (most recent call last):\ncan only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    \nself._shutdown_workers()\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n    Traceback (most recent call last):\nif w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    \nself._shutdown_workers() \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive():  \n ^ ^ ^ ^^ ^^ ^ ^ ^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n  ^ ^ \n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'\n     ^ ^ ^ ^  ^ ^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 0.4632, F1: 0.8167, Acc: 0.8709\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a5776c81bab4615b6bba68c390b3fc2"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.7658, F1: 0.6167, Acc: 0.7557, Thresh: 0.0731\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3dea671bab42268c5f21ca5244c382"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2042, F1: 0.9208, Acc: 0.9468\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"691c3f19b81341ce85fc3fee907e3182"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.1691, F1: 0.6544, Acc: 0.7923, Thresh: 0.0068\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cdd9204595549b39ce9782792f7f25c"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0783, F1: 0.9681, Acc: 0.9789\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0411a68b309447fa8a4f1d69310e22e2"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.2757, F1: 0.6569, Acc: 0.7923, Thresh: 0.0070\n\nEarly stopping at epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbf1a3cf17945d38eaf306cac44b5df"}},"metadata":{}},{"name":"stdout","text":"\nFold 1 Best F1: 0.6660\n\n================================================================================\nFOLD 2/3\n================================================================================\n\nApplying balanced strategy:\nBalanced: 1279 samples\nReject: 1013, Accept: 266\nRatio: 3.81:1\n\n\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29dc90cee56b47c2a93c6d7354c45784"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6105, F1: 0.5843, Acc: 0.6317\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1df6e34a1c41407d8b833bd531a9593b"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.5693, F1: 0.6379, Acc: 0.7609, Thresh: 0.2043\n✓ Best model saved (F1: 0.6379)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b1c0d832534dd989bd4206be612cd2"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.3695, F1: 0.8412, Acc: 0.8905\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca230112c024521adb4e86bf62547fc"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.0702, F1: 0.6625, Acc: 0.8464, Thresh: 0.0514\n✓ Best model saved (F1: 0.6625)\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cd90198c5424ee7bdd462b277648405"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.1798, F1: 0.9460, Acc: 0.9640\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3acbdd08964647a3a396e5ae824d473a"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.2264, F1: 0.6664, Acc: 0.8499, Thresh: 0.0291\n✓ Best model saved (F1: 0.6664)\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3400b004da04dbb8f27212b934c728b"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.4375, F1: 0.6625, Acc: 0.8499, Thresh: 0.0083\n\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d269b69e784fb1aad10c04e6ce4189"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0553, F1: 0.9869, Acc: 0.9914\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cda25a5bffd45d38ae1d20bb2064444"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.5099, F1: 0.6744, Acc: 0.8569, Thresh: 0.0075\n✓ Best model saved (F1: 0.6744)\n\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9382805e3714e6895a70020c71e3aca"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0282, F1: 0.9928, Acc: 0.9953\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4db7dc61fad4e78a1a57854a9a98c89"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.6592, F1: 0.6621, Acc: 0.8360, Thresh: 0.0020\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf8f8e9a05de4d1c9fa44912917d1cfe"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Best F1: 0.6744\n\n================================================================================\nFOLD 3/3\n================================================================================\n\nApplying balanced strategy:\nBalanced: 1279 samples\nReject: 1013, Accept: 266\nRatio: 3.81:1\n\n\nEpoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef146704ba942438b2e0b506878835f"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6545, F1: 0.5566, Acc: 0.6130\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168cd5f7ee8d47968f7a1360585185a2"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.6619, F1: 0.6996, Acc: 0.8656, Thresh: 0.8786\n✓ Best model saved (F1: 0.6996)\n\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7fc829b73d465c9902fbffcdba1737"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.4548, F1: 0.8017, Acc: 0.8632\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4016d3fbc551454a8cc2a9f0ecc14322"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 0.7778, F1: 0.6765, Acc: 0.8429, Thresh: 0.1841\n\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a73ebaacdcaa474292fc6a14c6cbeb36"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.2245, F1: 0.9304, Acc: 0.9547\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cc63d2830804e6da93eaf18ebdec729"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    Exception ignored in: self._shutdown_workers()\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    if w.is_alive():self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n      if w.is_alive():\n           ^ ^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n\n\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                    ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\nAssertionError: : can only test a child process\ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nTraceback (most recent call last):\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nself._shutdown_workers()    \nif w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n     if w.is_alive():\n          ^ ^ ^ ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^\nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process'\n                   ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionErrorAssertionError: : can only test a child processcan only test a child process\n\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nException ignored in: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n    Traceback (most recent call last):\nself._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    self._shutdown_workers()    \n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nif w.is_alive():    \nif w.is_alive():  \n          ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    \nassert self._parent_pid == os.getpid(), 'can only test a child process'\n                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError: ^\ncan only test a child process\nAssertionError: can only test a child processException ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\nException ignored in: Traceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nself._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nif w.is_alive():    \nif w.is_alive(): \n         ^ ^ ^ ^^ ^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n^ \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError^^: ^can only test a child process\n\nAssertionError: Exception ignored in: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0><function _MultiProcessingDataLoaderIter.__del__ at 0x7fccc4f1e5c0>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\nself._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\nif w.is_alive():    \nif w.is_alive():\n             ^ ^^^^^^^^^^^^^^^^^^^^^^\n^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n \n                    ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Val - Loss: 1.2293, F1: 0.6896, Acc: 0.8517, Thresh: 0.0139\n\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95083fe57f54a96a9afc57310f2e3be"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.1068, F1: 0.9691, Acc: 0.9797\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1703bde4aa4b4f8b2ea9d222e31827"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.6300, F1: 0.6605, Acc: 0.8482, Thresh: 0.0031\n\nEarly stopping at epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/36 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f362c0271f944688b0ecc3a3dc43f1a"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Best F1: 0.6996\n\n================================================================================\nMODEL 3 RESULTS\n================================================================================\nAverage F1: 0.6800 ± 0.0142\n\nGenerating test predictions...\n✓ Model 3 complete\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Ensemble Predictions","metadata":{}},{"cell_type":"code","source":"print(f'\\n{\"#\"*80}')\nprint('ENSEMBLE PREDICTIONS')\nprint(f'{\"#\"*80}\\n')\n\n# Weighted ensemble\noof_probs_ensemble = np.zeros(len(train_df))\ntest_probs_ensemble = np.zeros(len(test_df))\n\ntotal_weight = sum(all_model_weights)\n\nfor oof_probs, test_probs, weight in zip(\n    all_model_oof_probs, all_model_test_probs, all_model_weights\n):\n    oof_probs_ensemble += oof_probs * (weight / total_weight)\n    test_probs_ensemble += test_probs * (weight / total_weight)\n\n# Find optimal ensemble threshold\nensemble_threshold, ensemble_f1 = find_optimal_threshold(\n    train_df['label'].values,\n    oof_probs_ensemble\n)\n\nprint(f'Ensemble Threshold: {ensemble_threshold:.4f}')\n\n# OOF evaluation\noof_preds_ensemble = (oof_probs_ensemble >= ensemble_threshold).astype(int)\noof_f1 = f1_score(train_df['label'].values, oof_preds_ensemble, average='macro')\noof_acc = accuracy_score(train_df['label'].values, oof_preds_ensemble)\n\nprint(f'\\nOOF Macro F1: {oof_f1:.4f}')\nprint(f'OOF Accuracy: {oof_acc:.4f}')\nprint('\\nClassification Report:')\nprint(classification_report(\n    train_df['label'].values,\n    oof_preds_ensemble,\n    target_names=['Reject', 'Accept']\n))\n\n# Test predictions\ntest_preds_ensemble = (test_probs_ensemble >= ensemble_threshold).astype(int)\n\nprint(f'\\nTest Prediction Distribution:')\nprint(f'Reject: {(test_preds_ensemble == 0).sum()}')\nprint(f'Accept: {(test_preds_ensemble == 1).sum()}')\nprint(f'Accept rate: {(test_preds_ensemble == 1).sum() / len(test_preds_ensemble) * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:39:04.694633Z","iopub.execute_input":"2026-02-11T14:39:04.694976Z","iopub.status.idle":"2026-02-11T14:39:04.717860Z","shell.execute_reply.started":"2026-02-11T14:39:04.694942Z","shell.execute_reply":"2026-02-11T14:39:04.717264Z"}},"outputs":[{"name":"stdout","text":"\n################################################################################\nENSEMBLE PREDICTIONS\n################################################################################\n\nEnsemble Threshold: 0.4701\n\nOOF Macro F1: 0.6835\nOOF Accuracy: 0.8482\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.89      0.91      1520\n      Accept       0.39      0.55      0.46       199\n\n    accuracy                           0.85      1719\n   macro avg       0.66      0.72      0.68      1719\nweighted avg       0.87      0.85      0.86      1719\n\n\nTest Prediction Distribution:\nReject: 8985\nAccept: 1190\nAccept rate: 11.70%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Create submission\ntest_df['Prediction_Accept_Reject'] = [\n    'Accept' if p == 1 else 'Reject' for p in test_preds_ensemble\n]\ntest_df['Confidence_Score'] = test_probs_ensemble\n\noutput_cols = ['ID_New', 'Article Title', 'Prediction_Accept_Reject', 'Confidence_Score']\nsubmission = test_df[output_cols].copy()\n\n# Save\nsubmission.to_csv(f'{CFG.output_dir}/solution3_predictions.csv', index=False)\nprint(f'\\n✓ Predictions saved to solution3_predictions.csv')\n\n# Show samples\nprint(f'\\nSample predictions:')\nprint(submission.head(10))\n\nprint(f'\\n{\"=\"*80}')\nprint('SOLUTION 3 COMPLETE!')\nprint(f'{\"=\"*80}')\nprint(f'✓ OOF Macro F1: {oof_f1:.4f}')\nprint(f'✓ OOF Accuracy: {oof_acc:.4f}')\nprint(f'✓ {len(CFG.model_configs)} models trained')\nprint(f'✓ Multiple sampling strategies used')\nprint(f'✓ Weighted ensemble applied')\nprint(f'✓ Test predictions generated')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T14:39:19.828771Z","iopub.execute_input":"2026-02-11T14:39:19.829345Z","iopub.status.idle":"2026-02-11T14:39:19.908450Z","shell.execute_reply.started":"2026-02-11T14:39:19.829317Z","shell.execute_reply":"2026-02-11T14:39:19.907897Z"}},"outputs":[{"name":"stdout","text":"\n✓ Predictions saved to solution3_predictions.csv\n\nSample predictions:\n        ID_New                                      Article Title  \\\n0      OA_3712                                                NaN   \n1     WoS_1385   It ' s one thing after another, after another...   \n2  Scopus_5109  \"A Return to and of the Land\": Indigenous Know...   \n3  Scopus_4859  \"I see my culture starting to disappear\": Anis...   \n4  Scopus_1176  \"Impact of Climate Change on Coastal Cities: A...   \n5  Scopus_1477  \"Smart city\" and its implementation in concept...   \n6      OA_1940  \"The farm has an insatiable appetite\": A food ...   \n7  Scopus_3724  \"We want to have a positive impact\": Fragile e...   \n8  Scopus_1613  \"When you have stress because you don't have f...   \n9      OA_3763  #36915 D37 – the green footprint of regional a...   \n\n  Prediction_Accept_Reject  Confidence_Score  \n0                   Accept          0.552934  \n1                   Reject          0.123619  \n2                   Reject          0.303545  \n3                   Accept          0.807598  \n4                   Reject          0.214327  \n5                   Accept          0.729578  \n6                   Reject          0.037313  \n7                   Reject          0.131745  \n8                   Reject          0.039404  \n9                   Reject          0.134416  \n\n================================================================================\nSOLUTION 3 COMPLETE!\n================================================================================\n✓ OOF Macro F1: 0.6835\n✓ OOF Accuracy: 0.8482\n✓ 3 models trained\n✓ Multiple sampling strategies used\n✓ Weighted ensemble applied\n✓ Test predictions generated\n","output_type":"stream"}],"execution_count":12}]}