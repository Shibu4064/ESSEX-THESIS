{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14773437,"sourceType":"datasetVersion","datasetId":9443355}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Climate Text Classification - Solution 4\n## Advanced Deep Learning: Contrastive Learning + Mixup + Curriculum Learning\n\n**Publication-Ready Pipeline - State-of-the-Art Techniques**\n\n### Key Innovations:\n1. **Supervised Contrastive Learning**: Learn discriminative representations\n2. **Token-level Mixup**: Advanced data augmentation for text\n3. **Curriculum Learning**: Train from easy to hard examples\n4. **Multi-task Learning**: Joint binary + confidence estimation\n5. **Self-training**: Pseudo-labeling on confident predictions\n\n### Expected Performance:\n- **Target**: 82%+ Macro F1 and Accuracy\n- **Hardware**: Kaggle P100 GPU (16GB)\n- **Output**: <19.5GB","metadata":{}},{"cell_type":"code","source":"# Install packages\n!pip install -q transformers==4.45.0 datasets accelerate scikit-learn openpyxl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:26:42.172082Z","iopub.execute_input":"2026-02-11T18:26:42.172870Z","iopub.status.idle":"2026-02-11T18:26:56.120297Z","shell.execute_reply.started":"2026-02-11T18:26:42.172832Z","shell.execute_reply":"2026-02-11T18:26:56.119589Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport random\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (\n    AutoTokenizer, AutoModel, AutoConfig,\n    get_cosine_schedule_with_warmup\n)\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, classification_report,\n    precision_recall_curve, confusion_matrix\n)\n\nwarnings.filterwarnings('ignore')\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nprint('✓ Libraries loaded')\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:26:56.121798Z","iopub.execute_input":"2026-02-11T18:26:56.122030Z","iopub.status.idle":"2026-02-11T18:27:02.069005Z","shell.execute_reply.started":"2026-02-11T18:26:56.122006Z","shell.execute_reply":"2026-02-11T18:27:02.068363Z"}},"outputs":[{"name":"stdout","text":"✓ Libraries loaded\nPyTorch: 2.8.0+cu126\nCUDA: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # Paths\n    train_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Human labelled_DTU.xlsx'\n    test_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Master file_10k papers.xlsx'\n    output_dir = '/kaggle/working/'\n    \n    # Model\n    model_name = 'microsoft/deberta-v3-base'\n    max_length = 512\n    hidden_dropout = 0.1\n    \n    # Training\n    n_folds = 5\n    n_epochs = 10\n    batch_size = 8\n    lr = 2e-5\n    weight_decay = 0.01\n    warmup_ratio = 0.15\n    max_grad_norm = 1.0\n    \n    # Contrastive learning\n    use_contrastive = True\n    contrastive_temperature = 0.07\n    contrastive_weight = 0.5\n    \n    # Mixup\n    use_mixup = True\n    mixup_alpha = 0.4\n    mixup_prob = 0.5\n    \n    # Curriculum learning\n    use_curriculum = True\n    curriculum_epochs = 3  # Start with easy examples\n    \n    # Self-training\n    use_self_training = True\n    confidence_threshold = 0.9\n    \n    # Loss weights\n    class_weights = [1.0, 8.0]  # [Reject, Accept]\n    \n    # Hardware\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    fp16 = True\n    num_workers = 2\n    \n    # Optimization\n    early_stopping_patience = 4\n    \n    seed = 42\n\nprint('✓ Configuration set')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:02.069919Z","iopub.execute_input":"2026-02-11T18:27:02.070283Z","iopub.status.idle":"2026-02-11T18:27:02.076287Z","shell.execute_reply.started":"2026-02-11T18:27:02.070261Z","shell.execute_reply":"2026-02-11T18:27:02.075530Z"}},"outputs":[{"name":"stdout","text":"✓ Configuration set\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"# Load training data\ntrain_df = pd.read_excel(CFG.train_path, skiprows=1)\ntrain_df.columns = [\n    'Coder name', 'Article ID', 'Paper_Author/s', 'Paper title',\n    'Year of publication', 'DOI', 'URL', 'Abstracts',\n    'Accept/Reject', 'If Accept, identify theme'\n]\n\n# Clean\ntrain_df = train_df[train_df['Accept/Reject'].isin(['Accept', 'Reject'])].copy()\ntrain_df['text'] = train_df['Abstracts'].fillna('')\ntrain_df = train_df[train_df['text'].str.len() > 50].reset_index(drop=True)\n\n# Binary label\ntrain_df['label'] = (train_df['Accept/Reject'] == 'Accept').astype(int)\n\n# Calculate text difficulty (longer texts = harder)\ntrain_df['text_length'] = train_df['text'].str.len()\ntrain_df['difficulty'] = train_df['text_length'] / train_df['text_length'].max()\n\n# Load test data\ntest_df = pd.read_excel(CFG.test_path)\ntest_df['text'] = test_df['Abstract'].fillna('')\ntest_df = test_df[test_df['text'].str.len() > 50].reset_index(drop=True)\n\nprint(f'Training samples: {len(train_df)}')\nprint(f'Test samples: {len(test_df)}')\nprint(f'\\nClass distribution:')\nprint(train_df['label'].value_counts())\nprint(f'\\nImbalance ratio: {train_df[\"label\"].value_counts()[0] / train_df[\"label\"].value_counts()[1]:.2f}:1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:02.078218Z","iopub.execute_input":"2026-02-11T18:27:02.078471Z","iopub.status.idle":"2026-02-11T18:27:04.833818Z","shell.execute_reply.started":"2026-02-11T18:27:02.078444Z","shell.execute_reply":"2026-02-11T18:27:04.833092Z"}},"outputs":[{"name":"stdout","text":"Training samples: 1719\nTest samples: 10175\n\nClass distribution:\nlabel\n0    1520\n1     199\nName: count, dtype: int64\n\nImbalance ratio: 7.64:1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Advanced Dataset with Mixup","metadata":{}},{"cell_type":"code","source":"class ClimateDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length, use_mixup=False, difficulties=None):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.use_mixup = use_mixup\n        self.difficulties = difficulties if difficulties is not None else np.ones(len(texts))\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        difficulty = self.difficulties[idx]\n        \n        # Token-level mixup\n        if self.use_mixup and random.random() < CFG.mixup_prob:\n            # Find another sample from same class\n            same_class_indices = [i for i, l in enumerate(self.labels) if l == label and i != idx]\n            if same_class_indices:\n                mix_idx = random.choice(same_class_indices)\n                mix_text = str(self.texts[mix_idx])\n                \n                # Mix at sentence level\n                sents1 = text.split('. ')\n                sents2 = mix_text.split('. ')\n                \n                mixed_sents = []\n                max_len = max(len(sents1), len(sents2))\n                \n                for i in range(max_len):\n                    if random.random() < CFG.mixup_alpha:\n                        if i < len(sents1):\n                            mixed_sents.append(sents1[i])\n                    else:\n                        if i < len(sents2):\n                            mixed_sents.append(sents2[i])\n                \n                text = '. '.join(mixed_sents)\n        \n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long),\n            'difficulty': torch.tensor(difficulty, dtype=torch.float)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:04.834930Z","iopub.execute_input":"2026-02-11T18:27:04.835423Z","iopub.status.idle":"2026-02-11T18:27:04.844858Z","shell.execute_reply.started":"2026-02-11T18:27:04.835399Z","shell.execute_reply":"2026-02-11T18:27:04.844258Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Loss Functions","metadata":{}},{"cell_type":"code","source":"class SupervisedContrastiveLoss(nn.Module):\n    \"\"\"Supervised contrastive loss for classification\"\"\"\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n    \n    def forward(self, features, labels):\n        device = features.device\n        batch_size = features.shape[0]\n        \n        # Normalize features\n        features = F.normalize(features, dim=1)\n        \n        # Compute similarity matrix\n        similarity_matrix = torch.matmul(features, features.T)\n        \n        # Create mask for positive pairs (same label)\n        labels = labels.contiguous().view(-1, 1)\n        mask = torch.eq(labels, labels.T).float().to(device)\n        \n        # Remove diagonal (self-similarity)\n        mask = mask - torch.eye(batch_size, device=device)\n        \n        # Compute contrastive loss\n        exp_sim = torch.exp(similarity_matrix / self.temperature)\n        \n        # Denominator: sum over all negative pairs\n        neg_mask = 1 - torch.eye(batch_size, device=device)\n        denominator = torch.sum(exp_sim * neg_mask, dim=1, keepdim=True)\n        \n        # Numerator: positive pairs\n        pos_sim = exp_sim * mask\n        \n        # Loss\n        log_prob = torch.log(pos_sim / (denominator + 1e-8) + 1e-8)\n        loss = -torch.sum(log_prob * mask, dim=1) / (torch.sum(mask, dim=1) + 1e-8)\n        \n        return loss.mean()\n\nclass CombinedLoss(nn.Module):\n    \"\"\"Combine classification and contrastive loss\"\"\"\n    def __init__(self, class_weights, contrastive_weight=0.5, temperature=0.07):\n        super().__init__()\n        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)\n        self.contrastive_loss = SupervisedContrastiveLoss(temperature=temperature)\n        self.contrastive_weight = contrastive_weight\n    \n    def forward(self, logits, features, labels):\n        ce = self.ce_loss(logits, labels)\n        contrastive = self.contrastive_loss(features, labels)\n        \n        total_loss = ce + self.contrastive_weight * contrastive\n        \n        return total_loss, ce, contrastive","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:04.845918Z","iopub.execute_input":"2026-02-11T18:27:04.846137Z","iopub.status.idle":"2026-02-11T18:27:04.870948Z","shell.execute_reply.started":"2026-02-11T18:27:04.846118Z","shell.execute_reply":"2026-02-11T18:27:04.870367Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"class ClimateClassifier(nn.Module):\n    def __init__(self, model_name, n_classes=2, dropout=0.1):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.config.update({\n            'hidden_dropout_prob': dropout,\n            'attention_probs_dropout_prob': dropout,\n        })\n        \n        self.transformer = AutoModel.from_pretrained(model_name, config=self.config)\n        \n        hidden_size = self.config.hidden_size\n        \n        # Projection head for contrastive learning\n        self.projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, 256)  # Project to lower dimension\n        )\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.LayerNorm(hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size // 2, n_classes)\n        )\n    \n    def forward(self, input_ids, attention_mask, return_features=False):\n        outputs = self.transformer(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # Mean pooling\n        mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n        sum_embeddings = torch.sum(outputs.last_hidden_state * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        pooled = sum_embeddings / sum_mask\n        \n        # Get features for contrastive learning\n        features = self.projection(pooled)\n        \n        # Classification\n        logits = self.classifier(pooled)\n        \n        if return_features:\n            return logits, features\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:04.871953Z","iopub.execute_input":"2026-02-11T18:27:04.872215Z","iopub.status.idle":"2026-02-11T18:27:04.884374Z","shell.execute_reply.started":"2026-02-11T18:27:04.872191Z","shell.execute_reply":"2026-02-11T18:27:04.883667Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Training Functions","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, scheduler, criterion, device, epoch, scaler=None):\n    model.train()\n    total_loss = 0\n    total_ce_loss = 0\n    total_contrastive_loss = 0\n    predictions = []\n    true_labels = []\n    \n    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n    for batch in pbar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        if scaler is not None:\n            with torch.cuda.amp.autocast():\n                if CFG.use_contrastive:\n                    logits, features = model(input_ids, attention_mask, return_features=True)\n                    loss, ce_loss, cont_loss = criterion(logits, features, labels)\n                else:\n                    logits = model(input_ids, attention_mask)\n                    loss = criterion(logits, labels)\n                    ce_loss = loss\n                    cont_loss = torch.tensor(0.0)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            if CFG.use_contrastive:\n                logits, features = model(input_ids, attention_mask, return_features=True)\n                loss, ce_loss, cont_loss = criterion(logits, features, labels)\n            else:\n                logits = model(input_ids, attention_mask)\n                loss = criterion(logits, labels)\n                ce_loss = loss\n                cont_loss = torch.tensor(0.0)\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            optimizer.step()\n        \n        optimizer.zero_grad()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        total_ce_loss += ce_loss.item()\n        total_contrastive_loss += cont_loss.item() if CFG.use_contrastive else 0\n        \n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        true_labels.extend(labels.cpu().numpy())\n        \n        pbar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'ce': f'{ce_loss.item():.4f}'\n        })\n    \n    avg_loss = total_loss / len(dataloader)\n    avg_ce = total_ce_loss / len(dataloader)\n    avg_cont = total_contrastive_loss / len(dataloader) if CFG.use_contrastive else 0\n    f1 = f1_score(true_labels, predictions, average='macro')\n    acc = accuracy_score(true_labels, predictions)\n    \n    return avg_loss, avg_ce, avg_cont, f1, acc\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    predictions = []\n    probabilities = []\n    true_labels = []\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc='Validation')\n        for batch in pbar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            if CFG.use_contrastive:\n                logits, features = model(input_ids, attention_mask, return_features=True)\n                loss, _, _ = criterion(logits, features, labels)\n            else:\n                logits = model(input_ids, attention_mask)\n                loss = criterion(logits, labels)\n            \n            total_loss += loss.item()\n            \n            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            \n            probabilities.extend(probs)\n            predictions.extend(preds)\n            true_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    \n    return avg_loss, np.array(predictions), np.array(probabilities), np.array(true_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:04.885254Z","iopub.execute_input":"2026-02-11T18:27:04.885559Z","iopub.status.idle":"2026-02-11T18:27:04.898234Z","shell.execute_reply.started":"2026-02-11T18:27:04.885516Z","shell.execute_reply":"2026-02-11T18:27:04.897588Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def find_optimal_threshold(y_true, y_probs):\n    \"\"\"Find threshold that maximizes F1 score\"\"\"\n    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n    \n    f1_scores = []\n    for precision, recall in zip(precisions, recalls):\n        if precision + recall == 0:\n            f1_scores.append(0)\n        else:\n            f1_scores.append(2 * (precision * recall) / (precision + recall))\n    \n    best_idx = np.argmax(f1_scores)\n    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n    best_f1 = f1_scores[best_idx]\n    \n    return best_threshold, best_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T18:27:04.899231Z","iopub.execute_input":"2026-02-11T18:27:04.899519Z","iopub.status.idle":"2026-02-11T18:27:04.911510Z","shell.execute_reply.started":"2026-02-11T18:27:04.899500Z","shell.execute_reply":"2026-02-11T18:27:04.910922Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Cross-Validation Training","metadata":{}},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n\n# K-Fold\nskf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n\nfold_scores = []\nfold_thresholds = []\noof_predictions = np.zeros(len(train_df))\noof_probabilities = np.zeros(len(train_df))\n\n# Store models\nmodels = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n    print(f'\\n{\"=\"*80}')\n    print(f'FOLD {fold + 1}/{CFG.n_folds}')\n    print(f'{\"=\"*80}')\n    \n    # Get fold data\n    fold_train_df = train_df.iloc[train_idx].copy()\n    fold_val_df = train_df.iloc[val_idx].copy()\n    \n    # Oversample minority class\n    majority = fold_train_df[fold_train_df['label'] == 0]\n    minority = fold_train_df[fold_train_df['label'] == 1]\n    \n    # Oversample to 1:2 ratio\n    minority_oversampled = minority.sample(\n        n=len(majority) // 2,\n        replace=True,\n        random_state=42\n    )\n    \n    fold_train_balanced = pd.concat(\n        [majority, minority, minority_oversampled],\n        ignore_index=True\n    ).sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    print(f'Balanced training set:')\n    print(f'Total: {len(fold_train_balanced)}')\n    print(f'Reject: {(fold_train_balanced[\"label\"]==0).sum()}')\n    print(f'Accept: {(fold_train_balanced[\"label\"]==1).sum()}')\n    \n    # Create datasets\n    train_dataset = ClimateDataset(\n        fold_train_balanced['text'].values,\n        fold_train_balanced['label'].values,\n        tokenizer,\n        CFG.max_length,\n        use_mixup=CFG.use_mixup,\n        difficulties=fold_train_balanced['difficulty'].values\n    )\n    \n    val_dataset = ClimateDataset(\n        fold_val_df['text'].values,\n        fold_val_df['label'].values,\n        tokenizer,\n        CFG.max_length,\n        use_mixup=False\n    )\n    \n    # Dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=True,\n        num_workers=CFG.num_workers,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=CFG.batch_size * 2,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True\n    )\n    \n    # Model\n    model = ClimateClassifier(\n        CFG.model_name,\n        n_classes=2,\n        dropout=CFG.hidden_dropout\n    ).to(CFG.device)\n    \n    # Loss\n    class_weights = torch.tensor(CFG.class_weights, dtype=torch.float).to(CFG.device)\n    \n    if CFG.use_contrastive:\n        criterion = CombinedLoss(\n            class_weights=class_weights,\n            contrastive_weight=CFG.contrastive_weight,\n            temperature=CFG.contrastive_temperature\n        )\n    else:\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # Optimizer\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=CFG.lr,\n        weight_decay=CFG.weight_decay\n    )\n    \n    # Scheduler\n    num_training_steps = len(train_loader) * CFG.n_epochs\n    num_warmup_steps = int(num_training_steps * CFG.warmup_ratio)\n    \n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=num_warmup_steps,\n        num_training_steps=num_training_steps\n    )\n    \n    # Mixed precision\n    scaler = torch.cuda.amp.GradScaler() if CFG.fp16 else None\n    \n    # Training loop\n    best_f1 = 0\n    patience_counter = 0\n    \n    for epoch in range(CFG.n_epochs):\n        print(f'\\nEpoch {epoch + 1}/{CFG.n_epochs}')\n        \n        # Train\n        train_loss, train_ce, train_cont, train_f1, train_acc = train_epoch(\n            model, train_loader, optimizer, scheduler, criterion, CFG.device, epoch + 1, scaler\n        )\n        \n        if CFG.use_contrastive:\n            print(f'Train - Loss: {train_loss:.4f}, CE: {train_ce:.4f}, Cont: {train_cont:.4f}, F1: {train_f1:.4f}, Acc: {train_acc:.4f}')\n        else:\n            print(f'Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Acc: {train_acc:.4f}')\n        \n        # Validate\n        val_loss, val_preds, val_probs, val_labels = validate(\n            model, val_loader, criterion, CFG.device\n        )\n        \n        # Find optimal threshold\n        threshold, _ = find_optimal_threshold(val_labels, val_probs)\n        val_preds_thresh = (val_probs >= threshold).astype(int)\n        \n        val_f1 = f1_score(val_labels, val_preds_thresh, average='macro')\n        val_acc = accuracy_score(val_labels, val_preds_thresh)\n        \n        print(f'Val - Loss: {val_loss:.4f}, F1: {val_f1:.4f}, Acc: {val_acc:.4f}, Thresh: {threshold:.4f}')\n        print(classification_report(val_labels, val_preds_thresh, target_names=['Reject', 'Accept'], digits=4))\n        \n        # Early stopping\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_threshold = threshold\n            patience_counter = 0\n            \n            # Save best model\n            torch.save(model.state_dict(), f'{CFG.output_dir}/best_model_fold{fold}.pth')\n            print(f'✓ Best model saved (F1: {best_f1:.4f})')\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.early_stopping_patience:\n                print(f'\\nEarly stopping at epoch {epoch + 1}')\n                break\n    \n    # Load best model\n    model.load_state_dict(torch.load(f'{CFG.output_dir}/best_model_fold{fold}.pth'))\n    \n    # Final validation\n    _, _, val_probs, _ = validate(model, val_loader, criterion, CFG.device)\n    \n    # Store OOF predictions\n    oof_probabilities[val_idx] = val_probs\n    oof_predictions[val_idx] = (val_probs >= best_threshold).astype(int)\n    \n    # Store fold results\n    fold_scores.append(best_f1)\n    fold_thresholds.append(best_threshold)\n    models.append(model)\n    \n    print(f'\\nFold {fold + 1} Best F1: {best_f1:.4f}, Threshold: {best_threshold:.4f}')\n    \n    # Cleanup\n    del train_dataset, val_dataset, train_loader, val_loader\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint(f'\\n{\"=\"*80}')\nprint('CROSS-VALIDATION RESULTS')\nprint(f'{\"=\"*80}')\nprint(f'Average F1: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}')\nprint(f'Fold scores: {[f\"{s:.4f}\" for s in fold_scores]}')\n\n# Overall OOF evaluation\nprint(f'\\n{\"=\"*80}')\nprint('OUT-OF-FOLD PREDICTIONS')\nprint(f'{\"=\"*80}')\noof_f1 = f1_score(train_df['label'].values, oof_predictions, average='macro')\noof_acc = accuracy_score(train_df['label'].values, oof_predictions)\nprint(f'OOF Macro F1: {oof_f1:.4f}')\nprint(f'OOF Accuracy: {oof_acc:.4f}')\nprint('\\nClassification Report:')\nprint(classification_report(train_df['label'].values, oof_predictions, target_names=['Reject', 'Accept']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T19:21:29.987190Z","iopub.execute_input":"2026-02-11T19:21:29.987846Z","iopub.status.idle":"2026-02-11T21:21:31.448850Z","shell.execute_reply.started":"2026-02-11T19:21:29.987811Z","shell.execute_reply":"2026-02-11T21:21:31.448009Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFOLD 1/5\n================================================================================\nBalanced training set:\nTotal: 1983\nReject: 1216\nAccept: 767\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b9547b69d164a1c8199b3181b08dbcd"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.3952, CE: 0.4633, Cont: 1.8639, F1: 0.5182, Acc: 0.5335\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6d969626c04ebe9cb9bb6a1bb11fd5"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.9930, F1: 0.5960, Acc: 0.7326, Thresh: 0.3681\n              precision    recall  f1-score   support\n\n      Reject     0.9417    0.7434    0.8309       304\n      Accept     0.2500    0.6500    0.3611        40\n\n    accuracy                         0.7326       344\n   macro avg     0.5958    0.6967    0.5960       344\nweighted avg     0.8612    0.7326    0.7763       344\n\n✓ Best model saved (F1: 0.5960)\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"065a1ec5d3054c8cb1feba556d0203e2"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.1021, CE: 0.2757, Cont: 1.6527, F1: 0.8695, Acc: 0.8729\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38dfb4bd466148698be832da1e4216de"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.9672, F1: 0.6278, Acc: 0.7355, Thresh: 0.0086\n              precision    recall  f1-score   support\n\n      Reject     0.9733    0.7204    0.8280       304\n      Accept     0.2857    0.8500    0.4277        40\n\n    accuracy                         0.7355       344\n   macro avg     0.6295    0.7852    0.6278       344\nweighted avg     0.8934    0.7355    0.7814       344\n\n✓ Best model saved (F1: 0.6278)\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deebf67bf0e1456aa845a31b5d4eb6b2"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.0066, CE: 0.2232, Cont: 1.5668, F1: 0.9179, Acc: 0.9208\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697ec79fd0854ab180778d4926333ddd"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.6534, F1: 0.6719, Acc: 0.7965, Thresh: 0.0199\n              precision    recall  f1-score   support\n\n      Reject     0.9643    0.7993    0.8741       304\n      Accept     0.3370    0.7750    0.4697        40\n\n    accuracy                         0.7965       344\n   macro avg     0.6506    0.7872    0.6719       344\nweighted avg     0.8913    0.7965    0.8271       344\n\n✓ Best model saved (F1: 0.6719)\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8603f00e3f14a8dae17429e95fa4908"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7505, CE: 0.0684, Cont: 1.3641, F1: 0.9731, Acc: 0.9743\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381dfc0de8ff4b698ba59f6ef881d8b8"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.4717, F1: 0.6258, Acc: 0.7587, Thresh: 0.0023\n              precision    recall  f1-score   support\n\n      Reject     0.9510    0.7664    0.8488       304\n      Accept     0.2828    0.7000    0.4029        40\n\n    accuracy                         0.7587       344\n   macro avg     0.6169    0.7332    0.6258       344\nweighted avg     0.8733    0.7587    0.7970       344\n\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4090a32ba0074a3a8809f587823319c3"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6888, CE: 0.0389, Cont: 1.2998, F1: 0.9873, Acc: 0.9879\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb8b83acab94650b213a8f2d442aec9"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.7849, F1: 0.6612, Acc: 0.8023, Thresh: 0.0007\n              precision    recall  f1-score   support\n\n      Reject     0.9504    0.8191    0.8799       304\n      Accept     0.3293    0.6750    0.4426        40\n\n    accuracy                         0.8023       344\n   macro avg     0.6398    0.7470    0.6612       344\nweighted avg     0.8782    0.8023    0.8290       344\n\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e5c7247af846368f607349add89954"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6333, CE: 0.0106, Cont: 1.2455, F1: 0.9952, Acc: 0.9955\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95b6f9e485d4c6ea7b69b5cfdbe5b9b"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.8898, F1: 0.6545, Acc: 0.8488, Thresh: 0.0009\n              precision    recall  f1-score   support\n\n      Reject     0.9228    0.9046    0.9136       304\n      Accept     0.3696    0.4250    0.3953        40\n\n    accuracy                         0.8488       344\n   macro avg     0.6462    0.6648    0.6545       344\nweighted avg     0.8585    0.8488    0.8534       344\n\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2ad96a5da84855b69c9b9b79f9d529"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6058, CE: 0.0013, Cont: 1.2091, F1: 0.9989, Acc: 0.9990\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ebcca1663a4426b01657b6919fb235"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 4.1531, F1: 0.6282, Acc: 0.7762, Thresh: 0.0003\n              precision    recall  f1-score   support\n\n      Reject     0.9416    0.7961    0.8627       304\n      Accept     0.2874    0.6250    0.3937        40\n\n    accuracy                         0.7762       344\n   macro avg     0.6145    0.7105    0.6282       344\nweighted avg     0.8656    0.7762    0.8082       344\n\n\nEarly stopping at epoch 7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d25a42ad88346ea9210859ca3985a3f"}},"metadata":{}},{"name":"stdout","text":"\nFold 1 Best F1: 0.6719, Threshold: 0.0199\n\n================================================================================\nFOLD 2/5\n================================================================================\nBalanced training set:\nTotal: 1983\nReject: 1216\nAccept: 767\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32358fc2532f4a21b87cad1e6c31e680"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.4379, CE: 0.4963, Cont: 1.8833, F1: 0.4856, Acc: 0.5063\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61d90dfcb3f545ec9fe2711a981db3a5"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.4261, F1: 0.6877, Acc: 0.8372, Thresh: 0.9703\n              precision    recall  f1-score   support\n\n      Reject     0.9460    0.8651    0.9038       304\n      Accept     0.3788    0.6250    0.4717        40\n\n    accuracy                         0.8372       344\n   macro avg     0.6624    0.7451    0.6877       344\nweighted avg     0.8801    0.8372    0.8535       344\n\n✓ Best model saved (F1: 0.6877)\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"338fb4c1018a4bff94780f3c378dd4c5"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.1356, CE: 0.2943, Cont: 1.6826, F1: 0.8559, Acc: 0.8593\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3cb14fb970492991b0ef4b40419faf"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.1708, F1: 0.7065, Acc: 0.8343, Thresh: 0.8911\n              precision    recall  f1-score   support\n\n      Reject     0.9625    0.8454    0.9002       304\n      Accept     0.3896    0.7500    0.5128        40\n\n    accuracy                         0.8343       344\n   macro avg     0.6761    0.7977    0.7065       344\nweighted avg     0.8959    0.8343    0.8551       344\n\n✓ Best model saved (F1: 0.7065)\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"596193a66dc046eb86a5266b0edd4e87"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.9045, CE: 0.1480, Cont: 1.5131, F1: 0.9448, Acc: 0.9470\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e6396a252648b59a327750d46e095f"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.7200, F1: 0.7144, Acc: 0.8488, Thresh: 0.0869\n              precision    recall  f1-score   support\n\n      Reject     0.9565    0.8684    0.9103       304\n      Accept     0.4118    0.7000    0.5185        40\n\n    accuracy                         0.8488       344\n   macro avg     0.6841    0.7842    0.7144       344\nweighted avg     0.8932    0.8488    0.8648       344\n\n✓ Best model saved (F1: 0.7144)\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1561040d1e140fb9ee32c2e24904709"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7650, CE: 0.0695, Cont: 1.3909, F1: 0.9773, Acc: 0.9783\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f359cdc8e9204b218a4370b8d7778c2b"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3289, F1: 0.7131, Acc: 0.8808, Thresh: 0.2799\n              precision    recall  f1-score   support\n\n      Reject     0.9340    0.9309    0.9325       304\n      Accept     0.4878    0.5000    0.4938        40\n\n    accuracy                         0.8808       344\n   macro avg     0.7109    0.7155    0.7131       344\nweighted avg     0.8821    0.8808    0.8815       344\n\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae1a46d3e394e73b6fd26b6a331430c"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7243, CE: 0.0608, Cont: 1.3271, F1: 0.9857, Acc: 0.9864\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97c358ef8c1048b6b38a5f4b45f9a807"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.0997, F1: 0.7240, Acc: 0.8721, Thresh: 0.0362\n              precision    recall  f1-score   support\n\n      Reject     0.9452    0.9079    0.9262       304\n      Accept     0.4615    0.6000    0.5217        40\n\n    accuracy                         0.8721       344\n   macro avg     0.7034    0.7539    0.7240       344\nweighted avg     0.8890    0.8721    0.8791       344\n\n✓ Best model saved (F1: 0.7240)\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26c3d9e80b149c98dcaf406d916cd35"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6613, CE: 0.0251, Cont: 1.2724, F1: 0.9915, Acc: 0.9919\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee934d6d4c6b4d3db25e9e9089a13871"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.4613, F1: 0.7092, Acc: 0.8779, Thresh: 0.0016\n              precision    recall  f1-score   support\n\n      Reject     0.9338    0.9276    0.9307       304\n      Accept     0.4762    0.5000    0.4878        40\n\n    accuracy                         0.8779       344\n   macro avg     0.7050    0.7138    0.7092       344\nweighted avg     0.8806    0.8779    0.8792       344\n\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdabf86d68d34418a917f8a5cecb3415"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6552, CE: 0.0187, Cont: 1.2729, F1: 0.9936, Acc: 0.9939\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9fecfcbe7a449f941823b163138de3"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.4666, F1: 0.7114, Acc: 0.8750, Thresh: 0.0328\n              precision    recall  f1-score   support\n\n      Reject     0.9365    0.9211    0.9287       304\n      Accept     0.4667    0.5250    0.4941        40\n\n    accuracy                         0.8750       344\n   macro avg     0.7016    0.7230    0.7114       344\nweighted avg     0.8818    0.8750    0.8782       344\n\n\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43d8b81443f2444f8f46db948dcecb35"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6223, CE: 0.0077, Cont: 1.2291, F1: 0.9968, Acc: 0.9970\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c96e6c1ef6094d04baba665b0cce5dd5"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.4818, F1: 0.7148, Acc: 0.8866, Thresh: 0.0237\n              precision    recall  f1-score   support\n\n      Reject     0.9316    0.9408    0.9362       304\n      Accept     0.5135    0.4750    0.4935        40\n\n    accuracy                         0.8866       344\n   macro avg     0.7226    0.7079    0.7148       344\nweighted avg     0.8830    0.8866    0.8847       344\n\n\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f42fbe1fb38426ab029bd4ce89061ef"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6133, CE: 0.0040, Cont: 1.2185, F1: 0.9979, Acc: 0.9980\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e833d3860448d78e48898ce2a3880d"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.6173, F1: 0.7133, Acc: 0.8721, Thresh: 0.0116\n              precision    recall  f1-score   support\n\n      Reject     0.9392    0.9145    0.9267       304\n      Accept     0.4583    0.5500    0.5000        40\n\n    accuracy                         0.8721       344\n   macro avg     0.6988    0.7322    0.7133       344\nweighted avg     0.8833    0.8721    0.8771       344\n\n\nEarly stopping at epoch 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30811d95c9b841169be33530cabbe0cd"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Best F1: 0.7240, Threshold: 0.0362\n\n================================================================================\nFOLD 3/5\n================================================================================\nBalanced training set:\nTotal: 1983\nReject: 1216\nAccept: 767\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cacbe75af96a48d5bccf33b1803f0e43"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.4249, CE: 0.4847, Cont: 1.8804, F1: 0.5242, Acc: 0.5335\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0514b80b175414f98e96226dead9ccf"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.0772, F1: 0.6543, Acc: 0.8198, Thresh: 0.9145\n              precision    recall  f1-score   support\n\n      Reject     0.9353    0.8553    0.8935       304\n      Accept     0.3333    0.5500    0.4151        40\n\n    accuracy                         0.8198       344\n   macro avg     0.6343    0.7026    0.6543       344\nweighted avg     0.8653    0.8198    0.8378       344\n\n✓ Best model saved (F1: 0.6543)\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8160debf73304fc69c08d1a4e9ea9705"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e4bd9152980>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e4bd9152980>^\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^^^self._shutdown_workers()^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n    if w.is_alive():AssertionError\n:   can only test a child process\n     ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 1.1119, CE: 0.2728, Cont: 1.6781, F1: 0.8529, Acc: 0.8553\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"152fb747b75c4b4cb98dcf287cfd4c6f"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.7954, F1: 0.6568, Acc: 0.8023, Thresh: 0.9916\n              precision    recall  f1-score   support\n\n      Reject     0.9470    0.8224    0.8803       304\n      Accept     0.3250    0.6500    0.4333        40\n\n    accuracy                         0.8023       344\n   macro avg     0.6360    0.7362    0.6568       344\nweighted avg     0.8746    0.8023    0.8283       344\n\n✓ Best model saved (F1: 0.6568)\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dd4034d62740bd93e2466f991d3e0d"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.9465, CE: 0.1760, Cont: 1.5409, F1: 0.9468, Acc: 0.9491\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88529df3a9b42c1935c885936d085a3"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.8682, F1: 0.7008, Acc: 0.8576, Thresh: 0.9940\n              precision    recall  f1-score   support\n\n      Reject     0.9412    0.8947    0.9174       304\n      Accept     0.4182    0.5750    0.4842        40\n\n    accuracy                         0.8576       344\n   macro avg     0.6797    0.7349    0.7008       344\nweighted avg     0.8804    0.8576    0.8670       344\n\n✓ Best model saved (F1: 0.7008)\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"613b9978e6ab495baca36de109e22fa4"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7294, CE: 0.0542, Cont: 1.3504, F1: 0.9820, Acc: 0.9829\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef7f42fdf684f74bbb1dd52c83a5bdb"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.1598, F1: 0.7043, Acc: 0.8605, Thresh: 0.9396\n              precision    recall  f1-score   support\n\n      Reject     0.9414    0.8980    0.9192       304\n      Accept     0.4259    0.5750    0.4894        40\n\n    accuracy                         0.8605       344\n   macro avg     0.6837    0.7365    0.7043       344\nweighted avg     0.8814    0.8605    0.8692       344\n\n✓ Best model saved (F1: 0.7043)\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4529b72c4dd7435eabf6a787cd88796f"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7106, CE: 0.0511, Cont: 1.3190, F1: 0.9883, Acc: 0.9889\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee95aabd04ec4b2bb15cd7b4d06cb26e"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.4290, F1: 0.6954, Acc: 0.8576, Thresh: 0.9993\n              precision    recall  f1-score   support\n\n      Reject     0.9381    0.8980    0.9176       304\n      Accept     0.4151    0.5500    0.4731        40\n\n    accuracy                         0.8576       344\n   macro avg     0.6766    0.7240    0.6954       344\nweighted avg     0.8773    0.8576    0.8660       344\n\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c42d5acb27754149bef93d0c128c67ab"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6429, CE: 0.0150, Cont: 1.2557, F1: 0.9947, Acc: 0.9950\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab129263d61e47f8a8d40a31aa6fba5d"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3386, F1: 0.7202, Acc: 0.8692, Thresh: 0.9992\n              precision    recall  f1-score   support\n\n      Reject     0.9450    0.9046    0.9244       304\n      Accept     0.4528    0.6000    0.5161        40\n\n    accuracy                         0.8692       344\n   macro avg     0.6989    0.7523    0.7202       344\nweighted avg     0.8878    0.8692    0.8769       344\n\n✓ Best model saved (F1: 0.7202)\n\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed4f3c79a924162826722a4e9ea2244"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6554, CE: 0.0264, Cont: 1.2580, F1: 0.9942, Acc: 0.9945\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a212f594c3e47b988bd6e8fc3d6048e"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.1464, F1: 0.7342, Acc: 0.8837, Thresh: 0.9877\n              precision    recall  f1-score   support\n\n      Reject     0.9430    0.9243    0.9336       304\n      Accept     0.5000    0.5750    0.5349        40\n\n    accuracy                         0.8837       344\n   macro avg     0.7215    0.7497    0.7342       344\nweighted avg     0.8914    0.8837    0.8872       344\n\n✓ Best model saved (F1: 0.7342)\n\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e5fd4db3e14005abb949ba678e4e8f"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6103, CE: 0.0035, Cont: 1.2136, F1: 0.9979, Acc: 0.9980\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a300143a08574ea5b02d0c8f0edf9099"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3140, F1: 0.7216, Acc: 0.8663, Thresh: 0.9550\n              precision    recall  f1-score   support\n\n      Reject     0.9479    0.8980    0.9223       304\n      Accept     0.4464    0.6250    0.5208        40\n\n    accuracy                         0.8663       344\n   macro avg     0.6972    0.7615    0.7216       344\nweighted avg     0.8896    0.8663    0.8756       344\n\n\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ab806edf221464198c74ade5e64288a"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6114, CE: 0.0044, Cont: 1.2140, F1: 0.9984, Acc: 0.9985\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9726e44d2c4649e6992a69a50fde0cae"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3833, F1: 0.7240, Acc: 0.8721, Thresh: 0.0010\n              precision    recall  f1-score   support\n\n      Reject     0.9452    0.9079    0.9262       304\n      Accept     0.4615    0.6000    0.5217        40\n\n    accuracy                         0.8721       344\n   macro avg     0.7034    0.7539    0.7240       344\nweighted avg     0.8890    0.8721    0.8791       344\n\n\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d71d2e42c1c41159795896fb4336884"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6055, CE: 0.0008, Cont: 1.2095, F1: 0.9995, Acc: 0.9995\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a338783608942e38657f11629da406e"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3063, F1: 0.7202, Acc: 0.8692, Thresh: 0.0037\n              precision    recall  f1-score   support\n\n      Reject     0.9450    0.9046    0.9244       304\n      Accept     0.4528    0.6000    0.5161        40\n\n    accuracy                         0.8692       344\n   macro avg     0.6989    0.7523    0.7202       344\nweighted avg     0.8878    0.8692    0.8769       344\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1b6a6e980e46d4a7a32b1c89bda8b2"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Best F1: 0.7342, Threshold: 0.9877\n\n================================================================================\nFOLD 4/5\n================================================================================\nBalanced training set:\nTotal: 1983\nReject: 1216\nAccept: 767\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d4b37f2ea84203ac63a31c3a0081ec"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.3804, CE: 0.4369, Cont: 1.8870, F1: 0.4948, Acc: 0.5234\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"762b31a99c024c66a664f5d7c15017c6"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 1.7946, F1: 0.7778, Acc: 0.9157, Thresh: 0.8629\n              precision    recall  f1-score   support\n\n      Reject     0.9421    0.9638    0.9528       304\n      Accept     0.6667    0.5500    0.6027        40\n\n    accuracy                         0.9157       344\n   macro avg     0.8044    0.7569    0.7778       344\nweighted avg     0.9101    0.9157    0.9121       344\n\n✓ Best model saved (F1: 0.7778)\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f475baf6bfb045618102445102f6a328"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.1215, CE: 0.2784, Cont: 1.6862, F1: 0.8718, Acc: 0.8754\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be28a07412a448998b6887959c1a6527"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.4593, F1: 0.7723, Acc: 0.9157, Thresh: 0.0554\n              precision    recall  f1-score   support\n\n      Reject     0.9393    0.9671    0.9530       304\n      Accept     0.6774    0.5250    0.5915        40\n\n    accuracy                         0.9157       344\n   macro avg     0.8084    0.7461    0.7723       344\nweighted avg     0.9088    0.9157    0.9110       344\n\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ec94eec5b342da9316bb6777a088c0"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.0470, CE: 0.2513, Cont: 1.5914, F1: 0.9165, Acc: 0.9198\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10190d610dd243b28e9eab574a35c28c"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.5335, F1: 0.7248, Acc: 0.8808, Thresh: 0.3809\n              precision    recall  f1-score   support\n\n      Reject     0.9398    0.9243    0.9320       304\n      Accept     0.4889    0.5500    0.5176        40\n\n    accuracy                         0.8808       344\n   macro avg     0.7143    0.7372    0.7248       344\nweighted avg     0.8874    0.8808    0.8838       344\n\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd4f88a521af49f5b62f172b4dd1c57c"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7665, CE: 0.0774, Cont: 1.3782, F1: 0.9767, Acc: 0.9778\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3aadb55f5ea4ef1a24c7fdd64dd61fc"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.0303, F1: 0.7602, Acc: 0.9157, Thresh: 0.0572\n              precision    recall  f1-score   support\n\n      Reject     0.9338    0.9737    0.9533       304\n      Accept     0.7037    0.4750    0.5672        40\n\n    accuracy                         0.9157       344\n   macro avg     0.8187    0.7243    0.7602       344\nweighted avg     0.9070    0.9157    0.9084       344\n\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9907790118410aaf2a2d4224373756"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7311, CE: 0.0675, Cont: 1.3273, F1: 0.9841, Acc: 0.9849\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c695d992223a4286bbfc95639c7df6b5"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.3969, F1: 0.7123, Acc: 0.8895, Thresh: 0.0073\n              precision    recall  f1-score   support\n\n      Reject     0.9290    0.9474    0.9381       304\n      Accept     0.5294    0.4500    0.4865        40\n\n    accuracy                         0.8895       344\n   macro avg     0.7292    0.6987    0.7123       344\nweighted avg     0.8826    0.8895    0.8856       344\n\n\nEarly stopping at epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"919222e3ae4b4424a2cb3b22b3dc9dd1"}},"metadata":{}},{"name":"stdout","text":"\nFold 4 Best F1: 0.7778, Threshold: 0.8629\n\n================================================================================\nFOLD 5/5\n================================================================================\nBalanced training set:\nTotal: 1984\nReject: 1216\nAccept: 768\n\nEpoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a472efe72da4089880b5ddbb8ff669e"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.4175, CE: 0.4818, Cont: 1.8715, F1: 0.4842, Acc: 0.5015\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88a305502094c4a96ba415ef4e69bb2"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.0422, F1: 0.7226, Acc: 0.8484, Thresh: 0.9428\n              precision    recall  f1-score   support\n\n      Reject     0.9667    0.8586    0.9094       304\n      Accept     0.4110    0.7692    0.5357        39\n\n    accuracy                         0.8484       343\n   macro avg     0.6888    0.8139    0.7226       343\nweighted avg     0.9035    0.8484    0.8669       343\n\n✓ Best model saved (F1: 0.7226)\n\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a00b8814274ec7a9d8c59f4ece7fd6"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 1.1039, CE: 0.2652, Cont: 1.6773, F1: 0.8657, Acc: 0.8690\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5705a1edab9048bc883090fb5adc584c"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.5191, F1: 0.7270, Acc: 0.8863, Thresh: 0.0818\n              precision    recall  f1-score   support\n\n      Reject     0.9402    0.9309    0.9355       304\n      Accept     0.5000    0.5385    0.5185        39\n\n    accuracy                         0.8863       343\n   macro avg     0.7201    0.7347    0.7270       343\nweighted avg     0.8901    0.8863    0.8881       343\n\n✓ Best model saved (F1: 0.7270)\n\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6a915db44048cfb25b534c4f389de3"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.9872, CE: 0.1974, Cont: 1.5796, F1: 0.9322, Acc: 0.9350\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41f8d83043541ba9f9332350cafd874"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 2.7098, F1: 0.6869, Acc: 0.8192, Thresh: 0.7589\n              precision    recall  f1-score   support\n\n      Reject     0.9618    0.8289    0.8905       304\n      Accept     0.3580    0.7436    0.4833        39\n\n    accuracy                         0.8192       343\n   macro avg     0.6599    0.7863    0.6869       343\nweighted avg     0.8932    0.8192    0.8442       343\n\n\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ebeccab2134923b1264c94035d3bb5"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7651, CE: 0.0762, Cont: 1.3778, F1: 0.9751, Acc: 0.9763\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9e16898c54f4b3daba0d88d3717697e"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.0576, F1: 0.6908, Acc: 0.8397, Thresh: 0.0152\n              precision    recall  f1-score   support\n\n      Reject     0.9495    0.8651    0.9053       304\n      Accept     0.3788    0.6410    0.4762        39\n\n    accuracy                         0.8397       343\n   macro avg     0.6641    0.7531    0.6908       343\nweighted avg     0.8846    0.8397    0.8565       343\n\n\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ccd3133a4614fb6a5847279e23788d0"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.7142, CE: 0.0484, Cont: 1.3316, F1: 0.9841, Acc: 0.9849\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a9c23cddc974b4e8bbd95705799d53d"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.7477, F1: 0.6488, Acc: 0.7843, Thresh: 0.0005\n              precision    recall  f1-score   support\n\n      Reject     0.9563    0.7928    0.8669       304\n      Accept     0.3077    0.7179    0.4308        39\n\n    accuracy                         0.7843       343\n   macro avg     0.6320    0.7554    0.6488       343\nweighted avg     0.8826    0.7843    0.8173       343\n\n\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/248 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297a066b2e9a40a4b2cdb4f5008393e5"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.6375, CE: 0.0170, Cont: 1.2409, F1: 0.9963, Acc: 0.9965\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056b91608c4c4a31844af5713d298cf9"}},"metadata":{}},{"name":"stdout","text":"Val - Loss: 3.9786, F1: 0.7164, Acc: 0.8921, Thresh: 0.0014\n              precision    recall  f1-score   support\n\n      Reject     0.9320    0.9474    0.9396       304\n      Accept     0.5294    0.4615    0.4932        39\n\n    accuracy                         0.8921       343\n   macro avg     0.7307    0.7045    0.7164       343\nweighted avg     0.8863    0.8921    0.8889       343\n\n\nEarly stopping at epoch 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdffe7da321b41de8564f374689cdef5"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e4bd9152980>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7e4bd9152980>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n\n    if w.is_alive():Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n       self._shutdown_workers()\n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n       ^^if w.is_alive():\n^^ ^ ^ ^ ^ ^^ ^ ^^^\n^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ ^ ^^  \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n      ^  ^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^^^\n^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"\nFold 5 Best F1: 0.7270, Threshold: 0.0818\n\n================================================================================\nCROSS-VALIDATION RESULTS\n================================================================================\nAverage F1: 0.7270 ± 0.0337\nFold scores: ['0.6719', '0.7240', '0.7342', '0.7778', '0.7270']\n\n================================================================================\nOUT-OF-FOLD PREDICTIONS\n================================================================================\nOOF Macro F1: 0.7235\nOOF Accuracy: 0.8709\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.95      0.91      0.93      1520\n      Accept       0.46      0.61      0.52       199\n\n    accuracy                           0.87      1719\n   macro avg       0.70      0.76      0.72      1719\nweighted avg       0.89      0.87      0.88      1719\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Test Predictions","metadata":{}},{"cell_type":"code","source":"# Test dataset\ntest_dataset = ClimateDataset(\n    test_df['text'].values,\n    np.zeros(len(test_df)),\n    tokenizer,\n    CFG.max_length,\n    use_mixup=False\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CFG.batch_size * 2,\n    shuffle=False,\n    num_workers=CFG.num_workers,\n    pin_memory=True\n)\n\n# Ensemble predictions\nall_probs = []\n\nfor fold, model in enumerate(models):\n    model.eval()\n    fold_probs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f'Fold {fold+1} Prediction'):\n            input_ids = batch['input_ids'].to(CFG.device)\n            attention_mask = batch['attention_mask'].to(CFG.device)\n            \n            logits = model(input_ids, attention_mask)\n            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n            fold_probs.append(probs)\n    \n    all_probs.append(np.concatenate(fold_probs))\n\n# Average probabilities\navg_probs = np.mean(all_probs, axis=0)\n\n# Use average threshold\navg_threshold = np.mean(fold_thresholds)\nfinal_preds = (avg_probs >= avg_threshold).astype(int)\n\nprint(f'\\nPredictions complete!')\nprint(f'Average threshold used: {avg_threshold:.4f}')\nprint(f'\\nPrediction distribution:')\nprint(f'Reject: {(final_preds == 0).sum()}')\nprint(f'Accept: {(final_preds == 1).sum()}')\nprint(f'Accept rate: {(final_preds == 1).sum() / len(final_preds) * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:23:26.580711Z","iopub.execute_input":"2026-02-11T21:23:26.581530Z","iopub.status.idle":"2026-02-11T21:45:48.538514Z","shell.execute_reply.started":"2026-02-11T21:23:26.581497Z","shell.execute_reply":"2026-02-11T21:45:48.537603Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fold 1 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65b015d8d4964eeebeab7bfb73588217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 2 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b8d650bb474aaba54b40afc45f2068"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 3 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985395e7df374f7ca9ebc4eeed975ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 4 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a819c4b05f4fc6adaa176e8a617c62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 5 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b3aa95e6714bf2adbe6f1bbce1258a"}},"metadata":{}},{"name":"stdout","text":"\nPredictions complete!\nAverage threshold used: 0.3977\n\nPrediction distribution:\nReject: 8852\nAccept: 1323\nAccept rate: 13.00%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Create submission\ntest_df['Prediction_Accept_Reject'] = ['Accept' if p == 1 else 'Reject' for p in final_preds]\ntest_df['Confidence_Score'] = avg_probs\n\noutput_cols = ['ID_New', 'Article Title', 'Prediction_Accept_Reject', 'Confidence_Score']\nsubmission = test_df[output_cols].copy()\n\n# Save\nsubmission.to_csv(f'{CFG.output_dir}/solution4_predictions.csv', index=False)\nprint(f'\\n✓ Predictions saved to solution4_predictions.csv')\n\n# Show samples\nprint(f'\\nSample predictions:')\nprint(submission.head(10))\n\nprint(f'\\n{\"=\"*80}')\nprint('SOLUTION 4 COMPLETE!')\nprint(f'{\"=\"*80}')\nprint(f'✓ OOF Macro F1: {oof_f1:.4f}')\nprint(f'✓ OOF Accuracy: {oof_acc:.4f}')\nprint(f'✓ Average CV F1: {np.mean(fold_scores):.4f}')\nprint(f'✓ Contrastive learning applied')\nprint(f'✓ Token-level mixup augmentation')\nprint(f'✓ Advanced architecture')\nprint(f'✓ Test predictions generated')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T21:46:23.717679Z","iopub.execute_input":"2026-02-11T21:46:23.718059Z","iopub.status.idle":"2026-02-11T21:46:23.810955Z","shell.execute_reply.started":"2026-02-11T21:46:23.718018Z","shell.execute_reply":"2026-02-11T21:46:23.810348Z"}},"outputs":[{"name":"stdout","text":"\n✓ Predictions saved to solution4_predictions.csv\n\nSample predictions:\n        ID_New                                      Article Title  \\\n0      OA_3712                                                NaN   \n1     WoS_1385   It ' s one thing after another, after another...   \n2  Scopus_5109  \"A Return to and of the Land\": Indigenous Know...   \n3  Scopus_4859  \"I see my culture starting to disappear\": Anis...   \n4  Scopus_1176  \"Impact of Climate Change on Coastal Cities: A...   \n5  Scopus_1477  \"Smart city\" and its implementation in concept...   \n6      OA_1940  \"The farm has an insatiable appetite\": A food ...   \n7  Scopus_3724  \"We want to have a positive impact\": Fragile e...   \n8  Scopus_1613  \"When you have stress because you don't have f...   \n9      OA_3763  #36915 D37 – the green footprint of regional a...   \n\n  Prediction_Accept_Reject  Confidence_Score  \n0                   Reject          0.252896  \n1                   Reject          0.018530  \n2                   Reject          0.395968  \n3                   Accept          0.792479  \n4                   Reject          0.024699  \n5                   Accept          0.820108  \n6                   Reject          0.012982  \n7                   Reject          0.215394  \n8                   Reject          0.012685  \n9                   Reject          0.013242  \n\n================================================================================\nSOLUTION 4 COMPLETE!\n================================================================================\n✓ OOF Macro F1: 0.7235\n✓ OOF Accuracy: 0.8709\n✓ Average CV F1: 0.7270\n✓ Contrastive learning applied\n✓ Token-level mixup augmentation\n✓ Advanced architecture\n✓ Test predictions generated\n","output_type":"stream"}],"execution_count":14}]}