{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14773437,"sourceType":"datasetVersion","datasetId":9443355}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Climate Text Classification - Solution 1\n## Advanced Data Augmentation + Focal Loss + Threshold Optimization\n\n**Publication-Ready Pipeline**\n\n### Key Innovations:\n1. **Multi-Strategy Data Augmentation**: Back-translation, paraphrasing, and synonym replacement\n2. **Adaptive Focal Loss**: Dynamic focusing on hard examples\n3. **Threshold Optimization**: F1-score maximization on validation set\n4. **Progressive Training**: Curriculum learning from easy to hard samples\n5. **Model Ensemble**: Multiple augmentation strategies\n\n### Expected Performance:\n- **Target**: 80%+ Macro F1 and Accuracy\n- **Hardware**: Kaggle P100 GPU (16GB)\n- **Output**: <19.5GB","metadata":{}},{"cell_type":"code","source":"# Install packages\n!pip install -q transformers==4.45.0 datasets accelerate scikit-learn openpyxl nlpaug torch-optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:22:55.710190Z","iopub.execute_input":"2026-02-10T20:22:55.710511Z","iopub.status.idle":"2026-02-10T20:23:12.345212Z","shell.execute_reply.started":"2026-02-10T20:22:55.710487Z","shell.execute_reply":"2026-02-10T20:23:12.344450Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport gc\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport random\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nfrom transformers import (\n    AutoTokenizer, AutoModel, AutoConfig,\n    get_linear_schedule_with_warmup,\n    get_cosine_schedule_with_warmup\n)\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, classification_report,\n    precision_recall_curve, roc_auc_score, confusion_matrix\n)\n\nwarnings.filterwarnings('ignore')\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(42)\n\nprint('✓ Libraries loaded')\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:23:34.257580Z","iopub.execute_input":"2026-02-10T20:23:34.257955Z","iopub.status.idle":"2026-02-10T20:23:40.904472Z","shell.execute_reply.started":"2026-02-10T20:23:34.257924Z","shell.execute_reply":"2026-02-10T20:23:40.903712Z"}},"outputs":[{"name":"stdout","text":"✓ Libraries loaded\nPyTorch: 2.8.0+cu126\nCUDA: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # Paths\n    train_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Human labelled_DTU.xlsx'\n    test_path = '/kaggle/input/datasets/hrithikmajumdar/climate-text-dataset/Master file_10k papers.xlsx'\n    output_dir = '/kaggle/working/'\n    \n    # Model\n    model_name = 'microsoft/deberta-v3-base'  # Strong baseline\n    max_length = 512\n    hidden_dropout = 0.1\n    attention_dropout = 0.1\n    \n    # Training\n    n_folds = 5\n    n_epochs = 8\n    batch_size = 8\n    grad_accum_steps = 2\n    lr = 1.5e-5\n    weight_decay = 0.01\n    warmup_ratio = 0.1\n    max_grad_norm = 1.0\n    \n    # Augmentation\n    aug_rate = 4  # Augment minority class 4x\n    aug_probability = 0.3\n    \n    # Loss\n    focal_alpha = 0.75  # Higher weight for minority class\n    focal_gamma = 3.0   # Strong focusing on hard examples\n    label_smoothing = 0.05\n    \n    # Class weights (7.64:1 imbalance)\n    class_weights = [1.0, 7.64]  # [Reject, Accept]\n    \n    # Hardware\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    fp16 = True\n    num_workers = 2\n    \n    # Optimization\n    early_stopping_patience = 3\n    use_swa = True  # Stochastic Weight Averaging\n    swa_start_epoch = 5\n    \n    seed = 42\n\nprint('✓ Configuration set')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:25:35.129176Z","iopub.execute_input":"2026-02-10T20:25:35.129533Z","iopub.status.idle":"2026-02-10T20:25:35.136152Z","shell.execute_reply.started":"2026-02-10T20:25:35.129511Z","shell.execute_reply":"2026-02-10T20:25:35.135262Z"}},"outputs":[{"name":"stdout","text":"✓ Configuration set\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Data Loading and Augmentation","metadata":{}},{"cell_type":"code","source":"# Load training data\ntrain_df = pd.read_excel(CFG.train_path, skiprows=1)\ntrain_df.columns = [\n    'Coder name', 'Article ID', 'Paper_Author/s', 'Paper title',\n    'Year of publication', 'DOI', 'URL', 'Abstracts',\n    'Accept/Reject', 'If Accept, identify theme'\n]\n\n# Clean\ntrain_df = train_df[train_df['Accept/Reject'].isin(['Accept', 'Reject'])].copy()\ntrain_df['text'] = train_df['Abstracts'].fillna('')\ntrain_df = train_df[train_df['text'].str.len() > 50].reset_index(drop=True)  # Remove very short texts\n\n# Binary label\ntrain_df['label'] = (train_df['Accept/Reject'] == 'Accept').astype(int)\n\nprint(f'Training samples: {len(train_df)}')\nprint(f'\\nClass distribution:')\nprint(train_df['label'].value_counts())\nprint(f'\\nImbalance ratio: {train_df[\"label\"].value_counts()[0] / train_df[\"label\"].value_counts()[1]:.2f}:1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:25:37.918492Z","iopub.execute_input":"2026-02-10T20:25:37.919364Z","iopub.status.idle":"2026-02-10T20:25:38.669945Z","shell.execute_reply.started":"2026-02-10T20:25:37.919332Z","shell.execute_reply":"2026-02-10T20:25:38.669255Z"}},"outputs":[{"name":"stdout","text":"Training samples: 1719\n\nClass distribution:\nlabel\n0    1520\n1     199\nName: count, dtype: int64\n\nImbalance ratio: 7.64:1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Simple but effective text augmentation\nclass TextAugmenter:\n    \"\"\"Multiple augmentation strategies for text data\"\"\"\n    \n    def __init__(self, aug_prob=0.3):\n        self.aug_prob = aug_prob\n        \n    def random_deletion(self, text, p=0.1):\n        \"\"\"Randomly delete words\"\"\"\n        words = text.split()\n        if len(words) == 1:\n            return text\n        \n        new_words = []\n        for word in words:\n            if random.random() > p:\n                new_words.append(word)\n        \n        if len(new_words) == 0:\n            return random.choice(words)\n        \n        return ' '.join(new_words)\n    \n    def random_swap(self, text, n=3):\n        \"\"\"Randomly swap words\"\"\"\n        words = text.split()\n        if len(words) < 2:\n            return text\n        \n        new_words = words.copy()\n        for _ in range(n):\n            idx1, idx2 = random.sample(range(len(new_words)), 2)\n            new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n        \n        return ' '.join(new_words)\n    \n    def synonym_replacement(self, text):\n        \"\"\"Simple synonym replacement using domain keywords\"\"\"\n        synonyms = {\n            'climate': ['climate', 'environmental', 'ecological'],\n            'change': ['change', 'shift', 'transformation'],\n            'mitigation': ['mitigation', 'reduction', 'abatement'],\n            'well-being': ['well-being', 'welfare', 'quality of life'],\n            'sustainable': ['sustainable', 'eco-friendly', 'green'],\n            'policy': ['policy', 'regulation', 'framework'],\n            'governance': ['governance', 'management', 'administration'],\n        }\n        \n        words = text.split()\n        new_words = []\n        \n        for word in words:\n            word_lower = word.lower().strip('.,!?;:')\n            if word_lower in synonyms and random.random() < 0.3:\n                new_words.append(random.choice(synonyms[word_lower]))\n            else:\n                new_words.append(word)\n        \n        return ' '.join(new_words)\n    \n    def augment(self, text, strategy='mixed'):\n        \"\"\"Apply augmentation strategy\"\"\"\n        if random.random() > self.aug_prob:\n            return text\n        \n        if strategy == 'deletion':\n            return self.random_deletion(text)\n        elif strategy == 'swap':\n            return self.random_swap(text)\n        elif strategy == 'synonym':\n            return self.synonym_replacement(text)\n        else:  # mixed\n            aug_type = random.choice(['deletion', 'swap', 'synonym'])\n            if aug_type == 'deletion':\n                return self.random_deletion(text)\n            elif aug_type == 'swap':\n                return self.random_swap(text)\n            else:\n                return self.synonym_replacement(text)\n\nprint('✓ Augmenter created')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:25:43.723733Z","iopub.execute_input":"2026-02-10T20:25:43.724241Z","iopub.status.idle":"2026-02-10T20:25:43.736467Z","shell.execute_reply.started":"2026-02-10T20:25:43.724174Z","shell.execute_reply":"2026-02-10T20:25:43.735629Z"}},"outputs":[{"name":"stdout","text":"✓ Augmenter created\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Augment minority class\ndef create_balanced_dataset(df, aug_rate=4):\n    \"\"\"Create balanced dataset through augmentation\"\"\"\n    augmenter = TextAugmenter(aug_prob=0.5)\n    \n    # Separate classes\n    majority = df[df['label'] == 0].copy()\n    minority = df[df['label'] == 1].copy()\n    \n    print(f'Original - Majority: {len(majority)}, Minority: {len(minority)}')\n    \n    # Augment minority class\n    augmented_samples = []\n    for _ in range(aug_rate):\n        for idx, row in minority.iterrows():\n            new_row = row.copy()\n            new_row['text'] = augmenter.augment(row['text'])\n            augmented_samples.append(new_row)\n    \n    aug_df = pd.DataFrame(augmented_samples)\n    \n    # Combine\n    balanced_df = pd.concat([majority, minority, aug_df], ignore_index=True)\n    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    print(f'Balanced - Total: {len(balanced_df)}, Accept: {(balanced_df[\"label\"]==1).sum()}')\n    print(f'New ratio: {(balanced_df[\"label\"]==0).sum() / (balanced_df[\"label\"]==1).sum():.2f}:1')\n    \n    return balanced_df\n\n# Create balanced dataset\nbalanced_train_df = create_balanced_dataset(train_df, aug_rate=CFG.aug_rate)\n\nprint('\\n✓ Balanced dataset created')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:25:48.507668Z","iopub.execute_input":"2026-02-10T20:25:48.508370Z","iopub.status.idle":"2026-02-10T20:25:48.636474Z","shell.execute_reply.started":"2026-02-10T20:25:48.508340Z","shell.execute_reply":"2026-02-10T20:25:48.635731Z"}},"outputs":[{"name":"stdout","text":"Original - Majority: 1520, Minority: 199\nBalanced - Total: 2515, Accept: 995\nNew ratio: 1.53:1\n\n✓ Balanced dataset created\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Load test data\ntest_df = pd.read_excel(CFG.test_path)\ntest_df['text'] = test_df['Abstract'].fillna('')\ntest_df = test_df[test_df['text'].str.len() > 50].reset_index(drop=True)\n\nprint(f'Test samples: {len(test_df)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:25:58.720817Z","iopub.execute_input":"2026-02-10T20:25:58.721495Z","iopub.status.idle":"2026-02-10T20:26:00.880968Z","shell.execute_reply.started":"2026-02-10T20:25:58.721463Z","shell.execute_reply":"2026-02-10T20:26:00.880285Z"}},"outputs":[{"name":"stdout","text":"Test samples: 10175\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"code","source":"class ClimateDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length, augment=False):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.augment = augment\n        if augment:\n            self.augmenter = TextAugmenter(aug_prob=0.3)\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        \n        # Apply augmentation during training\n        if self.augment and self.labels[idx] == 1:  # Only augment minority class\n            text = self.augmenter.augment(text)\n        \n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:04.531335Z","iopub.execute_input":"2026-02-10T20:26:04.531660Z","iopub.status.idle":"2026-02-10T20:26:04.538389Z","shell.execute_reply.started":"2026-02-10T20:26:04.531635Z","shell.execute_reply":"2026-02-10T20:26:04.537645Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n    def __init__(self, alpha=0.75, gamma=3.0, label_smoothing=0.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.label_smoothing = label_smoothing\n    \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        \n        # Apply alpha weighting\n        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n        \n        # Focal loss\n        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n        \n        return focal_loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:09.543844Z","iopub.execute_input":"2026-02-10T20:26:09.544611Z","iopub.status.idle":"2026-02-10T20:26:09.549603Z","shell.execute_reply.started":"2026-02-10T20:26:09.544582Z","shell.execute_reply":"2026-02-10T20:26:09.548936Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class ClimateClassifier(nn.Module):\n    def __init__(self, model_name, n_classes=2, dropout=0.1):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.config.update({\n            'hidden_dropout_prob': dropout,\n            'attention_probs_dropout_prob': dropout,\n        })\n        \n        self.transformer = AutoModel.from_pretrained(model_name, config=self.config)\n        \n        # Multi-layer classifier head\n        hidden_size = self.config.hidden_size\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.LayerNorm(hidden_size // 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size // 2, n_classes)\n        )\n    \n    def forward(self, input_ids, attention_mask):\n        outputs = self.transformer(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # Use [CLS] token + mean pooling\n        cls_output = outputs.last_hidden_state[:, 0]  # [CLS]\n        \n        # Mean pooling\n        mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size())\n        sum_embeddings = torch.sum(outputs.last_hidden_state * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        mean_output = sum_embeddings / sum_mask\n        \n        # Combine [CLS] and mean pooling\n        combined = cls_output + mean_output\n        \n        logits = self.classifier(combined)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:12.028436Z","iopub.execute_input":"2026-02-10T20:26:12.029102Z","iopub.status.idle":"2026-02-10T20:26:12.036499Z","shell.execute_reply.started":"2026-02-10T20:26:12.029074Z","shell.execute_reply":"2026-02-10T20:26:12.035696Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Training Functions","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, scheduler, criterion, device, scaler=None):\n    model.train()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n    \n    pbar = tqdm(dataloader, desc='Training')\n    for batch in pbar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        if scaler is not None:\n            with torch.cuda.amp.autocast():\n                logits = model(input_ids, attention_mask)\n                loss = criterion(logits, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            optimizer.step()\n        \n        optimizer.zero_grad()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        \n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        true_labels.extend(labels.cpu().numpy())\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n    \n    avg_loss = total_loss / len(dataloader)\n    f1 = f1_score(true_labels, predictions, average='macro')\n    acc = accuracy_score(true_labels, predictions)\n    \n    return avg_loss, f1, acc\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    predictions = []\n    probabilities = []\n    true_labels = []\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc='Validation')\n        for batch in pbar:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            \n            total_loss += loss.item()\n            \n            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            \n            probabilities.extend(probs)\n            predictions.extend(preds)\n            true_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    \n    return avg_loss, np.array(predictions), np.array(probabilities), np.array(true_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:16.308426Z","iopub.execute_input":"2026-02-10T20:26:16.308995Z","iopub.status.idle":"2026-02-10T20:26:16.322999Z","shell.execute_reply.started":"2026-02-10T20:26:16.308966Z","shell.execute_reply":"2026-02-10T20:26:16.322108Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def find_optimal_threshold(y_true, y_probs):\n    \"\"\"Find threshold that maximizes F1 score\"\"\"\n    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n    \n    f1_scores = []\n    for precision, recall in zip(precisions, recalls):\n        if precision + recall == 0:\n            f1_scores.append(0)\n        else:\n            f1_scores.append(2 * (precision * recall) / (precision + recall))\n    \n    best_idx = np.argmax(f1_scores)\n    best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n    best_f1 = f1_scores[best_idx]\n    \n    return best_threshold, best_f1\n\ndef evaluate_with_threshold(y_true, y_probs, threshold):\n    \"\"\"Evaluate using optimal threshold\"\"\"\n    y_pred = (y_probs >= threshold).astype(int)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    acc = accuracy_score(y_true, y_pred)\n    \n    print(f'\\nThreshold: {threshold:.4f}')\n    print(f'Macro F1: {f1:.4f}')\n    print(f'Accuracy: {acc:.4f}')\n    print('\\nClassification Report:')\n    print(classification_report(y_true, y_pred, target_names=['Reject', 'Accept']))\n    print('\\nConfusion Matrix:')\n    print(confusion_matrix(y_true, y_pred))\n    \n    return f1, acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:21.417897Z","iopub.execute_input":"2026-02-10T20:26:21.418232Z","iopub.status.idle":"2026-02-10T20:26:21.425055Z","shell.execute_reply.started":"2026-02-10T20:26:21.418206Z","shell.execute_reply":"2026-02-10T20:26:21.424266Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Cross-Validation Training","metadata":{}},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n\n# K-Fold Cross Validation on ORIGINAL data (not augmented)\nskf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n\nfold_scores = []\nfold_thresholds = []\noof_predictions = np.zeros(len(train_df))\noof_probabilities = np.zeros(len(train_df))\n\n# Store models for ensemble\nmodels = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n    print(f'\\n{\"=\"*80}')\n    print(f'FOLD {fold + 1}/{CFG.n_folds}')\n    print(f'{\"=\"*80}')\n    \n    # Get fold data\n    fold_train_df = train_df.iloc[train_idx].copy()\n    fold_val_df = train_df.iloc[val_idx].copy()\n    \n    # Augment training fold\n    fold_train_balanced = create_balanced_dataset(fold_train_df, aug_rate=CFG.aug_rate)\n    \n    # Create datasets\n    train_dataset = ClimateDataset(\n        fold_train_balanced['text'].values,\n        fold_train_balanced['label'].values,\n        tokenizer,\n        CFG.max_length,\n        augment=True  # Additional online augmentation\n    )\n    \n    val_dataset = ClimateDataset(\n        fold_val_df['text'].values,\n        fold_val_df['label'].values,\n        tokenizer,\n        CFG.max_length,\n        augment=False\n    )\n    \n    # Dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=CFG.batch_size,\n        shuffle=True,\n        num_workers=CFG.num_workers,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=CFG.batch_size * 2,\n        shuffle=False,\n        num_workers=CFG.num_workers,\n        pin_memory=True\n    )\n    \n    # Model\n    model = ClimateClassifier(\n        CFG.model_name,\n        n_classes=2,\n        dropout=CFG.hidden_dropout\n    ).to(CFG.device)\n    \n    # Loss\n    criterion = FocalLoss(\n        alpha=CFG.focal_alpha,\n        gamma=CFG.focal_gamma,\n        label_smoothing=CFG.label_smoothing\n    )\n    \n    # Optimizer\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=CFG.lr,\n        weight_decay=CFG.weight_decay\n    )\n    \n    # Scheduler\n    num_training_steps = len(train_loader) * CFG.n_epochs\n    num_warmup_steps = int(num_training_steps * CFG.warmup_ratio)\n    \n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=num_warmup_steps,\n        num_training_steps=num_training_steps\n    )\n    \n    # Mixed precision\n    scaler = torch.cuda.amp.GradScaler() if CFG.fp16 else None\n    \n    # Training loop\n    best_f1 = 0\n    patience_counter = 0\n    \n    for epoch in range(CFG.n_epochs):\n        print(f'\\nEpoch {epoch + 1}/{CFG.n_epochs}')\n        \n        # Train\n        train_loss, train_f1, train_acc = train_epoch(\n            model, train_loader, optimizer, scheduler, criterion, CFG.device, scaler\n        )\n        \n        print(f'Train - Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Acc: {train_acc:.4f}')\n        \n        # Validate\n        val_loss, val_preds, val_probs, val_labels = validate(\n            model, val_loader, criterion, CFG.device\n        )\n        \n        # Find optimal threshold\n        threshold, threshold_f1 = find_optimal_threshold(val_labels, val_probs)\n        \n        # Evaluate with optimal threshold\n        val_f1, val_acc = evaluate_with_threshold(val_labels, val_probs, threshold)\n        \n        # Early stopping\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_threshold = threshold\n            patience_counter = 0\n            \n            # Save best model\n            torch.save(model.state_dict(), f'{CFG.output_dir}/best_model_fold{fold}.pth')\n            print(f'✓ Best model saved (F1: {best_f1:.4f})')\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG.early_stopping_patience:\n                print(f'\\nEarly stopping at epoch {epoch + 1}')\n                break\n    \n    # Load best model\n    model.load_state_dict(torch.load(f'{CFG.output_dir}/best_model_fold{fold}.pth'))\n    \n    # Final validation\n    val_loss, val_preds, val_probs, val_labels = validate(\n        model, val_loader, criterion, CFG.device\n    )\n    \n    # Store OOF predictions\n    oof_probabilities[val_idx] = val_probs\n    oof_predictions[val_idx] = (val_probs >= best_threshold).astype(int)\n    \n    # Store fold results\n    fold_scores.append(best_f1)\n    fold_thresholds.append(best_threshold)\n    models.append(model)\n    \n    print(f'\\nFold {fold + 1} Best F1: {best_f1:.4f}, Threshold: {best_threshold:.4f}')\n    \n    # Cleanup\n    del train_dataset, val_dataset, train_loader, val_loader\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint(f'\\n{\"=\"*80}')\nprint('CROSS-VALIDATION RESULTS')\nprint(f'{\"=\"*80}')\nprint(f'Average F1: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}')\nprint(f'Average Threshold: {np.mean(fold_thresholds):.4f}')\nprint(f'Fold scores: {[f\"{s:.4f}\" for s in fold_scores]}')\n\n# Overall OOF evaluation\nprint(f'\\n{\"=\"*80}')\nprint('OUT-OF-FOLD PREDICTIONS')\nprint(f'{\"=\"*80}')\noof_f1 = f1_score(train_df['label'].values, oof_predictions, average='macro')\noof_acc = accuracy_score(train_df['label'].values, oof_predictions)\nprint(f'OOF Macro F1: {oof_f1:.4f}')\nprint(f'OOF Accuracy: {oof_acc:.4f}')\nprint('\\nClassification Report:')\nprint(classification_report(train_df['label'].values, oof_predictions, target_names=['Reject', 'Accept']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T20:26:26.777589Z","iopub.execute_input":"2026-02-10T20:26:26.778444Z","iopub.status.idle":"2026-02-10T21:52:08.254733Z","shell.execute_reply.started":"2026-02-10T20:26:26.778410Z","shell.execute_reply":"2026-02-10T21:52:08.254000Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90420bfb37af4e2ba65043061afa7061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95fc1bb0c06e4a65a0e4226f8003758f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2236a6a1846424fa8004eca683be547"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nFOLD 1/5\n================================================================================\nOriginal - Majority: 1216, Minority: 159\nBalanced - Total: 2011, Accept: 795\nNew ratio: 1.53:1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09eed3a87537432686b5376ed443a409"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5594dc68cc1642f8995f8f66c695d755"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0351, F1: 0.6116, Acc: 0.6121\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052863c65ccb4f33a277acdf71483af3"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.6622\nMacro F1: 0.6811\nAccuracy: 0.8605\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.93      0.91      0.92       304\n      Accept       0.41      0.47      0.44        40\n\n    accuracy                           0.86       344\n   macro avg       0.67      0.69      0.68       344\nweighted avg       0.87      0.86      0.86       344\n\n\nConfusion Matrix:\n[[277  27]\n [ 21  19]]\n✓ Best model saved (F1: 0.6811)\n\nEpoch 2/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40d492aabce4960bb675c617a7eee41"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0130, F1: 0.9039, Acc: 0.9065\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c8c25d4dcd14be5b26c9c863d372fae"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1440\nMacro F1: 0.5592\nAccuracy: 0.6570\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.64      0.77       304\n      Accept       0.23      0.80      0.35        40\n\n    accuracy                           0.66       344\n   macro avg       0.59      0.72      0.56       344\nweighted avg       0.87      0.66      0.72       344\n\n\nConfusion Matrix:\n[[194 110]\n [  8  32]]\n\nEpoch 3/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f00bae428164bb4a601212605fcc81c"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0062, F1: 0.9695, Acc: 0.9707\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201a447ce4bd42c7b4889c115c5f586e"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.3681\nMacro F1: 0.6643\nAccuracy: 0.8576\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.92      0.91      0.92       304\n      Accept       0.40      0.42      0.41        40\n\n    accuracy                           0.86       344\n   macro avg       0.66      0.67      0.66       344\nweighted avg       0.86      0.86      0.86       344\n\n\nConfusion Matrix:\n[[278  26]\n [ 23  17]]\n\nEpoch 4/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f54522a800443e83cc06da871e5123"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0019, F1: 0.9927, Acc: 0.9930\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e15f16e7294aecac9734a0847fea2f"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1979\nMacro F1: 0.6709\nAccuracy: 0.8517\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.93      0.90      0.91       304\n      Accept       0.39      0.47      0.43        40\n\n    accuracy                           0.85       344\n   macro avg       0.66      0.69      0.67       344\nweighted avg       0.87      0.85      0.86       344\n\n\nConfusion Matrix:\n[[274  30]\n [ 21  19]]\n\nEarly stopping at epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2caee74c78a84600b7d555a138128b4c"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^self._shutdown_workers()^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^^    ^if w.is_alive():\n\n   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'\n      ^ ^^ ^ ^ ^^ ^ ^ ^ ^^ \n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^ ^ ^^   ^ ^^ ^ ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError^^: ^can only test a child process^\n^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"\nFold 1 Best F1: 0.6811, Threshold: 0.6622\n\n================================================================================\nFOLD 2/5\n================================================================================\nOriginal - Majority: 1216, Minority: 159\nBalanced - Total: 2011, Accept: 795\nNew ratio: 1.53:1\n\nEpoch 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f04ba15a21b4f448f4e31e7db9a9061"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0394, F1: 0.6098, Acc: 0.6106\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae8f1852ce24efeb6c9fa2d365e0a63"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.2912\nMacro F1: 0.6715\nAccuracy: 0.8314\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.87      0.90       304\n      Accept       0.36      0.57      0.44        40\n\n    accuracy                           0.83       344\n   macro avg       0.65      0.72      0.67       344\nweighted avg       0.87      0.83      0.85       344\n\n\nConfusion Matrix:\n[[263  41]\n [ 17  23]]\n✓ Best model saved (F1: 0.6715)\n\nEpoch 2/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d3aad433c5d4ca2a5591cc2a0502954"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0182, F1: 0.8726, Acc: 0.8762\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d57b28644e42119b43237de306195d"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.4257\nMacro F1: 0.7328\nAccuracy: 0.8866\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.93      0.94       304\n      Accept       0.51      0.55      0.53        40\n\n    accuracy                           0.89       344\n   macro avg       0.73      0.74      0.73       344\nweighted avg       0.89      0.89      0.89       344\n\n\nConfusion Matrix:\n[[283  21]\n [ 18  22]]\n✓ Best model saved (F1: 0.7328)\n\nEpoch 3/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b52e945aca5547a491034d22f5a3451f"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0057, F1: 0.9741, Acc: 0.9751\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9637184dfc9345b495aa14d54b089777"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1355\nMacro F1: 0.6756\nAccuracy: 0.7965\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.97      0.80      0.87       304\n      Accept       0.34      0.80      0.48        40\n\n    accuracy                           0.80       344\n   macro avg       0.65      0.80      0.68       344\nweighted avg       0.90      0.80      0.83       344\n\n\nConfusion Matrix:\n[[242  62]\n [  8  32]]\n\nEpoch 4/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470b37f5fa184afab06eef67af3d781e"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0028, F1: 0.9896, Acc: 0.9901\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c304942681754e019dbe7479cf05bd5c"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.0918\nMacro F1: 0.7065\nAccuracy: 0.8343\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.85      0.90       304\n      Accept       0.39      0.75      0.51        40\n\n    accuracy                           0.83       344\n   macro avg       0.68      0.80      0.71       344\nweighted avg       0.90      0.83      0.86       344\n\n\nConfusion Matrix:\n[[257  47]\n [ 10  30]]\n\nEpoch 5/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d99bace09a445fa82651fe451994f8"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>^^\n^Traceback (most recent call last):\n^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n^^    ^self._shutdown_workers()\n^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n^    ^if w.is_alive():^\n^^  ^^ ^ ^^  ^ ^^^^^^^^^^^^^^^^^^\n^^AssertionError\n:   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\ncan only test a child process    \nassert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 0.0017, F1: 0.9917, Acc: 0.9920\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c2a3a6fc574a769fbd0465a95a4684"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.0985\nMacro F1: 0.6981\nAccuracy: 0.8227\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.97      0.83      0.89       304\n      Accept       0.37      0.78      0.50        40\n\n    accuracy                           0.82       344\n   macro avg       0.67      0.80      0.70       344\nweighted avg       0.90      0.82      0.85       344\n\n\nConfusion Matrix:\n[[252  52]\n [  9  31]]\n\nEarly stopping at epoch 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb8fd40867041aead2203ac8873f7ad"}},"metadata":{}},{"name":"stdout","text":"\nFold 2 Best F1: 0.7328, Threshold: 0.4257\n\n================================================================================\nFOLD 3/5\n================================================================================\nOriginal - Majority: 1216, Minority: 159\nBalanced - Total: 2011, Accept: 795\nNew ratio: 1.53:1\n\nEpoch 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac2017a25ef24ed99f1b794d379263d3"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0322, F1: 0.6525, Acc: 0.6534\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167fc278dcbf41cbb213c5eebcbc9c1b"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.6074\nMacro F1: 0.6360\nAccuracy: 0.7849\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.81      0.87       304\n      Accept       0.30      0.62      0.40        40\n\n    accuracy                           0.78       344\n   macro avg       0.62      0.72      0.64       344\nweighted avg       0.87      0.78      0.81       344\n\n\nConfusion Matrix:\n[[245  59]\n [ 15  25]]\n✓ Best model saved (F1: 0.6360)\n\nEpoch 2/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ff7315e14c4008a053992066ad6376"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>\n\n Traceback (most recent call last):\n    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n       self._shutdown_workers() \n   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n       if w.is_alive():\n^ ^ ^ ^  ^ ^ ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^^ ^  ^^  ^ ^^  ^^ ^ ^^^^^\n^AssertionError: ^^can only test a child process\n^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 0.0149, F1: 0.8778, Acc: 0.8807\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11709303305941bb9ccdb226da04d449"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.3065\nMacro F1: 0.6359\nAccuracy: 0.7529\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.97      0.75      0.84       304\n      Accept       0.29      0.80      0.43        40\n\n    accuracy                           0.75       344\n   macro avg       0.63      0.77      0.64       344\nweighted avg       0.89      0.75      0.79       344\n\n\nConfusion Matrix:\n[[227  77]\n [  8  32]]\n\nEpoch 3/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf6797bd14541a7ba39f03b335bb1e9"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0063, F1: 0.9679, Acc: 0.9692\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561665ae7f064944a2fede6b8639aa57"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.3787\nMacro F1: 0.6684\nAccuracy: 0.8285\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.86      0.90       304\n      Accept       0.35      0.57      0.44        40\n\n    accuracy                           0.83       344\n   macro avg       0.65      0.72      0.67       344\nweighted avg       0.87      0.83      0.85       344\n\n\nConfusion Matrix:\n[[262  42]\n [ 17  23]]\n✓ Best model saved (F1: 0.6684)\n\nEpoch 4/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d685a523594045fb814280ebccab02ba"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0028, F1: 0.9865, Acc: 0.9871\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281fbf2d5a4349f98aaf5677558f01af"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.2585\nMacro F1: 0.6746\nAccuracy: 0.8343\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.87      0.90       304\n      Accept       0.37      0.57      0.45        40\n\n    accuracy                           0.83       344\n   macro avg       0.65      0.72      0.67       344\nweighted avg       0.87      0.83      0.85       344\n\n\nConfusion Matrix:\n[[264  40]\n [ 17  23]]\n✓ Best model saved (F1: 0.6746)\n\nEpoch 5/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c205332f7a48ce98f8bdc50a6a996b"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0008, F1: 0.9943, Acc: 0.9945\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5e721ef5dca4e3e966fc7b1e0551045"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1115\nMacro F1: 0.6571\nAccuracy: 0.7849\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.79      0.87       304\n      Accept       0.32      0.75      0.45        40\n\n    accuracy                           0.78       344\n   macro avg       0.64      0.77      0.66       344\nweighted avg       0.89      0.78      0.82       344\n\n\nConfusion Matrix:\n[[240  64]\n [ 10  30]]\n\nEpoch 6/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6232cc05a03c4207ba8c6ee030a56be2"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0006, F1: 0.9969, Acc: 0.9970\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51b394ede324aacadc7fa7ec2dd5ed2"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1210\nMacro F1: 0.6558\nAccuracy: 0.7878\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.80      0.87       304\n      Accept       0.32      0.72      0.44        40\n\n    accuracy                           0.79       344\n   macro avg       0.64      0.76      0.66       344\nweighted avg       0.88      0.79      0.82       344\n\n\nConfusion Matrix:\n[[242  62]\n [ 11  29]]\n\nEpoch 7/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccfb511b609a4ea084adfc364f2f4bd1"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0002, F1: 0.9984, Acc: 0.9985\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f8b6c5c2caf4521904102a9390d443c"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1320\nMacro F1: 0.6613\nAccuracy: 0.7936\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.80      0.87       304\n      Accept       0.33      0.72      0.45        40\n\n    accuracy                           0.79       344\n   macro avg       0.64      0.76      0.66       344\nweighted avg       0.88      0.79      0.82       344\n\n\nConfusion Matrix:\n[[244  60]\n [ 11  29]]\n\nEarly stopping at epoch 7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3448272eb864570b5a294a13c096b30"}},"metadata":{}},{"name":"stdout","text":"\nFold 3 Best F1: 0.6746, Threshold: 0.2585\n\n================================================================================\nFOLD 4/5\n================================================================================\nOriginal - Majority: 1216, Minority: 159\nBalanced - Total: 2011, Accept: 795\nNew ratio: 1.53:1\n\nEpoch 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c50797824314d9ab86598830cef13f2"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0332, F1: 0.6396, Acc: 0.6405\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209c423aef624303a703ef4f464a805d"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.5446\nMacro F1: 0.7252\nAccuracy: 0.8983\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.93      0.96      0.94       304\n      Accept       0.58      0.45      0.51        40\n\n    accuracy                           0.90       344\n   macro avg       0.76      0.70      0.73       344\nweighted avg       0.89      0.90      0.89       344\n\n\nConfusion Matrix:\n[[291  13]\n [ 22  18]]\n✓ Best model saved (F1: 0.7252)\n\nEpoch 2/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bfd5e3f86bd43f39c30ea7de793a289"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0157, F1: 0.8997, Acc: 0.9030\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e4b31dc14644943a6fdd1d0620b37d6"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.2615\nMacro F1: 0.7007\nAccuracy: 0.8488\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.95      0.88      0.91       304\n      Accept       0.40      0.62      0.49        40\n\n    accuracy                           0.85       344\n   macro avg       0.68      0.75      0.70       344\nweighted avg       0.88      0.85      0.86       344\n\n\nConfusion Matrix:\n[[267  37]\n [ 15  25]]\n\nEpoch 3/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014238d9a7d44e628171c12dbaf8b449"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0047, F1: 0.9792, Acc: 0.9801\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81bde3ef0f2f4c819a6c46a10d78843f"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1309\nMacro F1: 0.7014\nAccuracy: 0.8372\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.86      0.90       304\n      Accept       0.39      0.70      0.50        40\n\n    accuracy                           0.84       344\n   macro avg       0.67      0.78      0.70       344\nweighted avg       0.89      0.84      0.86       344\n\n\nConfusion Matrix:\n[[260  44]\n [ 12  28]]\n\nEpoch 4/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4906144d8d466bb7dea550a59a4338"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0022, F1: 0.9943, Acc: 0.9945\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61ccc3c18543401cbc1da828a652b0a1"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1404\nMacro F1: 0.6737\nAccuracy: 0.8023\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.96      0.81      0.88       304\n      Accept       0.34      0.75      0.47        40\n\n    accuracy                           0.80       344\n   macro avg       0.65      0.78      0.67       344\nweighted avg       0.89      0.80      0.83       344\n\n\nConfusion Matrix:\n[[246  58]\n [ 10  30]]\n\nEarly stopping at epoch 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"512474bd3f8740348a76556d7bd0ee06"}},"metadata":{}},{"name":"stdout","text":"\nFold 4 Best F1: 0.7252, Threshold: 0.5446\n\n================================================================================\nFOLD 5/5\n================================================================================\nOriginal - Majority: 1216, Minority: 160\nBalanced - Total: 2016, Accept: 800\nNew ratio: 1.52:1\n\nEpoch 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3dcff3106f4be1a1ac83819847b2b5"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0373, F1: 0.6127, Acc: 0.6131\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d7cbeb55cb4ced89bf3643bdb65af1"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.5172\nMacro F1: 0.6367\nAccuracy: 0.7755\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.95      0.79      0.86       304\n      Accept       0.29      0.69      0.41        39\n\n    accuracy                           0.78       343\n   macro avg       0.62      0.74      0.64       343\nweighted avg       0.88      0.78      0.81       343\n\n\nConfusion Matrix:\n[[239  65]\n [ 12  27]]\n✓ Best model saved (F1: 0.6367)\n\nEpoch 2/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af69a1423ebc42b59d0f4fbcb6cb37c6"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0159, F1: 0.8809, Acc: 0.8839\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b562906a63f64f8c925ba71b62539788"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.5757\nMacro F1: 0.6784\nAccuracy: 0.8192\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.95      0.84      0.89       304\n      Accept       0.35      0.69      0.47        39\n\n    accuracy                           0.82       343\n   macro avg       0.65      0.76      0.68       343\nweighted avg       0.89      0.82      0.84       343\n\n\nConfusion Matrix:\n[[254  50]\n [ 12  27]]\n✓ Best model saved (F1: 0.6784)\n\nEpoch 3/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb522f219df0499a9e5afda4447f5965"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0053, F1: 0.9727, Acc: 0.9737\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4697197a7e004466a6e0c6916b44b556"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.3041\nMacro F1: 0.7226\nAccuracy: 0.8630\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.95      0.89      0.92       304\n      Accept       0.43      0.67      0.53        39\n\n    accuracy                           0.86       343\n   macro avg       0.69      0.78      0.72       343\nweighted avg       0.89      0.86      0.88       343\n\n\nConfusion Matrix:\n[[270  34]\n [ 13  26]]\n✓ Best model saved (F1: 0.7226)\n\nEpoch 4/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829d4ec2e7e9455799b59c6b1dad8666"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0029, F1: 0.9902, Acc: 0.9906\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72432e0c69844002ac202d9dabd7d1e2"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.3931\nMacro F1: 0.6896\nAccuracy: 0.8571\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.90      0.92       304\n      Accept       0.40      0.54      0.46        39\n\n    accuracy                           0.86       343\n   macro avg       0.67      0.72      0.69       343\nweighted avg       0.88      0.86      0.87       343\n\n\nConfusion Matrix:\n[[273  31]\n [ 18  21]]\n\nEpoch 5/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c61c7e0a514289a9905bab502f1896"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e42a7b2e5c0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Train - Loss: 0.0008, F1: 0.9938, Acc: 0.9940\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c07277148374d64a806e07b0c6a8601"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1297\nMacro F1: 0.6828\nAccuracy: 0.8513\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.89      0.91       304\n      Accept       0.39      0.54      0.45        39\n\n    accuracy                           0.85       343\n   macro avg       0.66      0.71      0.68       343\nweighted avg       0.88      0.85      0.86       343\n\n\nConfusion Matrix:\n[[271  33]\n [ 18  21]]\n\nEpoch 6/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac380aeb9081442387bfc4f8c78cbbc0"}},"metadata":{}},{"name":"stdout","text":"Train - Loss: 0.0011, F1: 0.9969, Acc: 0.9970\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc7bf4dbcfb435b88f1d7e93e330f04"}},"metadata":{}},{"name":"stdout","text":"\nThreshold: 0.1244\nMacro F1: 0.6614\nAccuracy: 0.8163\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.84      0.89       304\n      Accept       0.33      0.62      0.43        39\n\n    accuracy                           0.82       343\n   macro avg       0.64      0.73      0.66       343\nweighted avg       0.88      0.82      0.84       343\n\n\nConfusion Matrix:\n[[256  48]\n [ 15  24]]\n\nEarly stopping at epoch 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7513208cca8f495dabbdf2e62d860729"}},"metadata":{}},{"name":"stdout","text":"\nFold 5 Best F1: 0.7226, Threshold: 0.3041\n\n================================================================================\nCROSS-VALIDATION RESULTS\n================================================================================\nAverage F1: 0.7072 ± 0.0243\nAverage Threshold: 0.4390\nFold scores: ['0.6811', '0.7328', '0.6746', '0.7252', '0.7226']\n\n================================================================================\nOUT-OF-FOLD PREDICTIONS\n================================================================================\nOOF Macro F1: 0.7066\nOOF Accuracy: 0.8685\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Reject       0.94      0.91      0.92      1520\n      Accept       0.44      0.54      0.49       199\n\n    accuracy                           0.87      1719\n   macro avg       0.69      0.73      0.71      1719\nweighted avg       0.88      0.87      0.87      1719\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Test Predictions","metadata":{}},{"cell_type":"code","source":"# Test dataset\ntest_dataset = ClimateDataset(\n    test_df['text'].values,\n    np.zeros(len(test_df)),\n    tokenizer,\n    CFG.max_length,\n    augment=False\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=CFG.batch_size * 2,\n    shuffle=False,\n    num_workers=CFG.num_workers,\n    pin_memory=True\n)\n\n# Ensemble predictions\nall_probs = []\n\nfor fold, model in enumerate(models):\n    model.eval()\n    fold_probs = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=f'Fold {fold+1} Prediction'):\n            input_ids = batch['input_ids'].to(CFG.device)\n            attention_mask = batch['attention_mask'].to(CFG.device)\n            \n            logits = model(input_ids, attention_mask)\n            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n            fold_probs.append(probs)\n    \n    all_probs.append(np.concatenate(fold_probs))\n\n# Average probabilities\navg_probs = np.mean(all_probs, axis=0)\n\n# Use average threshold\navg_threshold = np.mean(fold_thresholds)\nfinal_preds = (avg_probs >= avg_threshold).astype(int)\n\nprint(f'\\nPredictions complete!')\nprint(f'Average threshold used: {avg_threshold:.4f}')\nprint(f'\\nPrediction distribution:')\nprint(f'Reject: {(final_preds == 0).sum()}')\nprint(f'Accept: {(final_preds == 1).sum()}')\nprint(f'Accept rate: {(final_preds == 1).sum() / len(final_preds) * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T21:52:30.267669Z","iopub.execute_input":"2026-02-10T21:52:30.268558Z","iopub.status.idle":"2026-02-10T22:15:01.277519Z","shell.execute_reply.started":"2026-02-10T21:52:30.268526Z","shell.execute_reply":"2026-02-10T22:15:01.276654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fold 1 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d41f3cf979409fbe94151e401c82d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 2 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751b8b96c8f94fc58d6b3102c9e21d8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 3 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efcf58099cb2479daec62a170291649b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 4 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547bb92895604530b47a7b4a95f770cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fold 5 Prediction:   0%|          | 0/636 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b4ab0d47f24948b1bfe0a1b91ae983"}},"metadata":{}},{"name":"stdout","text":"\nPredictions complete!\nAverage threshold used: 0.4390\n\nPrediction distribution:\nReject: 8816\nAccept: 1359\nAccept rate: 13.36%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Create submission\ntest_df['Prediction_Accept_Reject'] = ['Accept' if p == 1 else 'Reject' for p in final_preds]\ntest_df['Confidence_Score'] = avg_probs\n\noutput_cols = ['ID_New', 'Article Title', 'Prediction_Accept_Reject', 'Confidence_Score']\nsubmission = test_df[output_cols].copy()\n\n# Save\nsubmission.to_csv(f'{CFG.output_dir}/solution1_predictions.csv', index=False)\nprint(f'\\n✓ Predictions saved to solution1_predictions.csv')\n\n# Show samples\nprint(f'\\nSample predictions:')\nprint(submission.head(10))\n\nprint(f'\\n{\"=\"*80}')\nprint('SOLUTION 1 COMPLETE!')\nprint(f'{\"=\"*80}')\nprint(f'✓ OOF Macro F1: {oof_f1:.4f}')\nprint(f'✓ OOF Accuracy: {oof_acc:.4f}')\nprint(f'✓ Average CV F1: {np.mean(fold_scores):.4f}')\nprint(f'✓ Models saved for each fold')\nprint(f'✓ Test predictions generated')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T22:15:28.494526Z","iopub.execute_input":"2026-02-10T22:15:28.494918Z","iopub.status.idle":"2026-02-10T22:15:28.593691Z","shell.execute_reply.started":"2026-02-10T22:15:28.494880Z","shell.execute_reply":"2026-02-10T22:15:28.592784Z"}},"outputs":[{"name":"stdout","text":"\n✓ Predictions saved to solution1_predictions.csv\n\nSample predictions:\n        ID_New                                      Article Title  \\\n0      OA_3712                                                NaN   \n1     WoS_1385   It ' s one thing after another, after another...   \n2  Scopus_5109  \"A Return to and of the Land\": Indigenous Know...   \n3  Scopus_4859  \"I see my culture starting to disappear\": Anis...   \n4  Scopus_1176  \"Impact of Climate Change on Coastal Cities: A...   \n5  Scopus_1477  \"Smart city\" and its implementation in concept...   \n6      OA_1940  \"The farm has an insatiable appetite\": A food ...   \n7  Scopus_3724  \"We want to have a positive impact\": Fragile e...   \n8  Scopus_1613  \"When you have stress because you don't have f...   \n9      OA_3763  #36915 D37 – the green footprint of regional a...   \n\n  Prediction_Accept_Reject  Confidence_Score  \n0                   Accept          0.772829  \n1                   Reject          0.232518  \n2                   Reject          0.310131  \n3                   Accept          0.558925  \n4                   Reject          0.315004  \n5                   Accept          0.539809  \n6                   Reject          0.250142  \n7                   Reject          0.286068  \n8                   Reject          0.224995  \n9                   Reject          0.182376  \n\n================================================================================\nSOLUTION 1 COMPLETE!\n================================================================================\n✓ OOF Macro F1: 0.7066\n✓ OOF Accuracy: 0.8685\n✓ Average CV F1: 0.7072\n✓ Models saved for each fold\n✓ Test predictions generated\n","output_type":"stream"}],"execution_count":17}]}